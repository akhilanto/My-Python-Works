{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('C://Users//akhil//Desktop//HAP 880//Week 2//testclaims_hu.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('select * from highUtilizationPredictionV2wco', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.join(pd.get_dummies(df.race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>ELIX1</th>\n",
       "      <th>ELIX2</th>\n",
       "      <th>ELIX3</th>\n",
       "      <th>ELIX4</th>\n",
       "      <th>ELIX5</th>\n",
       "      <th>ELIX6</th>\n",
       "      <th>...</th>\n",
       "      <th>drugs_m11-12</th>\n",
       "      <th>HighUtilizationY2</th>\n",
       "      <th>claimCount</th>\n",
       "      <th>A</th>\n",
       "      <th>Am.N</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>71</td>\n",
       "      <td>PAT136597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>86</td>\n",
       "      <td>PAT119838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>70</td>\n",
       "      <td>PAT11289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>W</td>\n",
       "      <td>75</td>\n",
       "      <td>PAT178745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>W</td>\n",
       "      <td>77</td>\n",
       "      <td>PAT50922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index race  age patient_id  ELIX1  ELIX2  ELIX3  ELIX4  ELIX5  ELIX6 ...  \\\n",
       "0      0    B   71  PAT136597      0      0      0      0      0      1 ...   \n",
       "1      1    A   86  PAT119838      0      0      0      0      0      0 ...   \n",
       "2      2    W   70   PAT11289      1      0      0      0      0      0 ...   \n",
       "3      3    W   75  PAT178745      0      0      0      0      1      0 ...   \n",
       "4      4    W   77   PAT50922      0      0      0      0      1      0 ...   \n",
       "\n",
       "   drugs_m11-12  HighUtilizationY2  claimCount  A  Am.N  B  H  O  U  W  \n",
       "0             1                  1         160  0     0  1  0  0  0  0  \n",
       "1             0                  0          24  1     0  0  0  0  0  0  \n",
       "2             0                  0          52  0     0  0  0  0  0  1  \n",
       "3             0                  0          15  0     0  0  0  0  0  1  \n",
       "4             4                  0          66  0     0  0  0  0  0  1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove('index')\n",
    "cols.remove('race')\n",
    "cols.remove('patient_id')\n",
    "cols.remove('HighUtilizationY2')\n",
    "cols.remove('claimCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, ts = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"C\": [1.0,0.8,0.5,0.3,0.01], \"solver\":['liblinear','lbfgs'], \"class_weight\":[None, 'balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lr = []\n",
    "for c in params[\"C\"]:\n",
    "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=100)\n",
    "    scores = [c, cross_validate(lr, tr[cols], tr['HighUtilizationY2'], scoring=['roc_auc','accuracy','precision','recall'], cv=10)]\n",
    "    res_lr.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  {'fit_time': array([1.05224586, 0.96600151, 0.89401197, 0.9380424 , 0.94367051,\n",
       "          1.08036065, 1.25582385, 1.32149243, 1.25019145, 1.07657003]),\n",
       "   'score_time': array([0.02792478, 0.0259304 , 0.02991772, 0.02593088, 0.02792525,\n",
       "          0.03291941, 0.02792597, 0.02892447, 0.03390908, 0.02892065]),\n",
       "   'test_roc_auc': array([0.81666292, 0.82883554, 0.80197104, 0.79311171, 0.8215035 ,\n",
       "          0.82390593, 0.80202993, 0.81436264, 0.81400188, 0.8286222 ]),\n",
       "   'train_roc_auc': array([0.81553557, 0.81818532, 0.8159722 , 0.81421175, 0.81569027,\n",
       "          0.81277996, 0.8172362 , 0.81564582, 0.81723371, 0.82007311]),\n",
       "   'test_accuracy': array([0.93571597, 0.9348903 , 0.93677008, 0.93547245, 0.93830365,\n",
       "          0.93747788, 0.93723454, 0.93829637, 0.93640868, 0.93723454]),\n",
       "   'train_accuracy': array([0.93700354, 0.93733124, 0.93727963, 0.93731895, 0.93683396,\n",
       "          0.93718787, 0.93712316, 0.93697898, 0.93690033, 0.93700519]),\n",
       "   'test_precision': array([0.52873563, 0.48913043, 0.55462185, 0.50909091, 0.62264151,\n",
       "          0.60674157, 0.57657658, 0.625     , 0.5462963 , 0.60240964]),\n",
       "   'train_precision': array([0.56910569, 0.58836443, 0.58512931, 0.58058058, 0.56313646,\n",
       "          0.58127018, 0.57668067, 0.58201701, 0.57405281, 0.58488228]),\n",
       "   'test_recall': array([0.08363636, 0.08181818, 0.12021858, 0.10200364, 0.12021858,\n",
       "          0.09836066, 0.11657559, 0.11839709, 0.10746812, 0.09107468]),\n",
       "   'train_recall': array([0.11331445, 0.10845811, 0.10985232, 0.11733765, 0.11187538,\n",
       "          0.1092454 , 0.11106615, 0.09690471, 0.10115315, 0.09548857])}],\n",
       " [0.8,\n",
       "  {'fit_time': array([0.91635466, 0.99437189, 0.9651444 , 0.997334  , 1.05642915,\n",
       "          1.09478474, 1.16192675, 1.1436367 , 1.09485221, 1.05888367]),\n",
       "   'score_time': array([0.03091764, 0.0294075 , 0.02692628, 0.03142309, 0.03490639,\n",
       "          0.04153728, 0.04288578, 0.03490782, 0.03091741, 0.02991986]),\n",
       "   'test_roc_auc': array([0.81775044, 0.82998681, 0.80158023, 0.79870738, 0.82102516,\n",
       "          0.82546505, 0.80072361, 0.81710281, 0.81254023, 0.81932125]),\n",
       "   'train_roc_auc': array([0.81687604, 0.81988756, 0.81556233, 0.81877412, 0.81507145,\n",
       "          0.81347657, 0.8158527 , 0.81782002, 0.81590192, 0.81187273]),\n",
       "   'test_accuracy': array([0.93559802, 0.93571597, 0.93724195, 0.93559042, 0.93771381,\n",
       "          0.93688805, 0.93723454, 0.93817839, 0.9362907 , 0.93652666]),\n",
       "   'train_accuracy': array([0.936938  , 0.9372788 , 0.93709612, 0.93680775, 0.93678153,\n",
       "          0.93701747, 0.9372018 , 0.93674304, 0.93712316, 0.93709694]),\n",
       "   'test_precision': array([0.52272727, 0.5308642 , 0.57391304, 0.51376147, 0.59459459,\n",
       "          0.58333333, 0.57522124, 0.60504202, 0.53543307, 0.55445545]),\n",
       "   'train_precision': array([0.56858639, 0.59117305, 0.57643312, 0.56380753, 0.56048387,\n",
       "          0.57666667, 0.57524752, 0.56580427, 0.57185039, 0.57675906]),\n",
       "   'test_recall': array([0.08363636, 0.07818182, 0.12021858, 0.10200364, 0.12021858,\n",
       "          0.08925319, 0.11839709, 0.13114754, 0.12386157, 0.10200364]),\n",
       "   'train_recall': array([0.10987454, 0.10299474, 0.10985232, 0.10904309, 0.1124823 ,\n",
       "          0.10499697, 0.11753996, 0.10176006, 0.11753996, 0.1094477 ])}],\n",
       " [0.5,\n",
       "  {'fit_time': array([1.08900571, 1.03483868, 1.05983329, 1.01778889, 1.03538013,\n",
       "          1.04328728, 1.09507275, 0.995363  , 1.16285324, 1.01387   ]),\n",
       "   'score_time': array([0.03490591, 0.02927518, 0.0299201 , 0.02992082, 0.02792573,\n",
       "          0.03091741, 0.03092098, 0.03091788, 0.03590512, 0.02992105]),\n",
       "   'test_roc_auc': array([0.819187  , 0.82560533, 0.80491052, 0.79467725, 0.82258404,\n",
       "          0.82602909, 0.80338106, 0.81490332, 0.80836322, 0.82539788]),\n",
       "   'train_roc_auc': array([0.81959384, 0.81596433, 0.81914941, 0.81614132, 0.81730576,\n",
       "          0.81381492, 0.81848522, 0.8146612 , 0.8119796 , 0.81774155]),\n",
       "   'test_accuracy': array([0.93583392, 0.93595188, 0.93688805, 0.93582635, 0.93794975,\n",
       "          0.93747788, 0.9374705 , 0.93770647, 0.93829637, 0.93676262]),\n",
       "   'train_accuracy': array([0.93691178, 0.93697732, 0.93675532, 0.93717477, 0.93676843,\n",
       "          0.93696504, 0.93679547, 0.93671682, 0.93733288, 0.93691344]),\n",
       "   'test_precision': array([0.53488372, 0.53535354, 0.56140351, 0.52293578, 0.61616162,\n",
       "          0.6043956 , 0.59047619, 0.58536585, 0.62264151, 0.5631068 ]),\n",
       "   'train_precision': array([0.56753927, 0.56850716, 0.56197479, 0.57716049, 0.56390977,\n",
       "          0.56822811, 0.56670342, 0.56216216, 0.587473  , 0.5685654 ]),\n",
       "   'test_recall': array([0.08363636, 0.09636364, 0.11657559, 0.10382514, 0.11111111,\n",
       "          0.10018215, 0.1129326 , 0.13114754, 0.12021858, 0.10564663]),\n",
       "   'train_recall': array([0.1096722 , 0.11250506, 0.10823387, 0.11349383, 0.1062108 ,\n",
       "          0.11288691, 0.10398543, 0.10519927, 0.11005462, 0.10904309])}],\n",
       " [0.3,\n",
       "  {'fit_time': array([0.99605775, 1.08860016, 1.22310734, 1.15294886, 1.1688807 ,\n",
       "          1.05218697, 1.06498504, 1.04922128, 1.02482486, 1.16133308]),\n",
       "   'score_time': array([0.0289228 , 0.04487944, 0.03589487, 0.03889561, 0.03092051,\n",
       "          0.03291178, 0.03391027, 0.03490853, 0.03242111, 0.04089117]),\n",
       "   'test_roc_auc': array([0.81690579, 0.82502718, 0.80022835, 0.79490701, 0.8221776 ,\n",
       "          0.82632961, 0.80113446, 0.81765911, 0.81165694, 0.82373838]),\n",
       "   'train_roc_auc': array([0.81648507, 0.81536235, 0.81351246, 0.81576228, 0.8162752 ,\n",
       "          0.81452649, 0.81664806, 0.81766349, 0.81489471, 0.81679424]),\n",
       "   'test_accuracy': array([0.93536211, 0.93536211, 0.93724195, 0.93511856, 0.93771381,\n",
       "          0.93759585, 0.93758849, 0.93829637, 0.93711656, 0.93605474]),\n",
       "   'train_accuracy': array([0.93683314, 0.93701665, 0.93727963, 0.93716166, 0.93668978,\n",
       "          0.93676843, 0.93709694, 0.93680858, 0.93709694, 0.93686101]),\n",
       "   'test_precision': array([0.51190476, 0.51086957, 0.57024793, 0.49514563, 0.6039604 ,\n",
       "          0.60638298, 0.59803922, 0.61206897, 0.56666667, 0.53535354]),\n",
       "   'train_precision': array([0.56549521, 0.58087367, 0.58263598, 0.58106638, 0.55966209,\n",
       "          0.55979899, 0.58470588, 0.57011494, 0.57258065, 0.56832972]),\n",
       "   'test_recall': array([0.07818182, 0.08545455, 0.12568306, 0.09289617, 0.11111111,\n",
       "          0.10382514, 0.11111111, 0.12932605, 0.12386157, 0.09653916]),\n",
       "   'train_recall': array([0.10744638, 0.09955484, 0.1126846 , 0.10803156, 0.10722233,\n",
       "          0.1126846 , 0.10054623, 0.10034392, 0.11490997, 0.1060085 ])}],\n",
       " [0.01,\n",
       "  {'fit_time': array([1.07447195, 1.02787042, 1.07259083, 1.0661025 , 1.03647184,\n",
       "          1.07778025, 1.08766866, 1.09714746, 1.03327084, 1.03831983]),\n",
       "   'score_time': array([0.03291225, 0.03390765, 0.03690219, 0.03391075, 0.03590345,\n",
       "          0.03192186, 0.02991986, 0.03338408, 0.03091669, 0.03491259]),\n",
       "   'test_roc_auc': array([0.81329259, 0.8220341 , 0.80424538, 0.79690289, 0.82308215,\n",
       "          0.82777063, 0.80565017, 0.81883055, 0.8105588 , 0.82064664]),\n",
       "   'train_roc_auc': array([0.81255441, 0.8120928 , 0.81910957, 0.81711769, 0.81719777,\n",
       "          0.81535868, 0.81982851, 0.81937984, 0.81364277, 0.81296763]),\n",
       "   'test_accuracy': array([0.93618778, 0.93595188, 0.93700602, 0.93535449, 0.93783178,\n",
       "          0.93724195, 0.93758849, 0.93865031, 0.93758849, 0.93676262]),\n",
       "   'train_accuracy': array([0.93742299, 0.93751475, 0.9370568 , 0.93734517, 0.9370568 ,\n",
       "          0.93725341, 0.93700519, 0.93690033, 0.93738531, 0.93729356]),\n",
       "   'test_precision': array([0.55294118, 0.5443038 , 0.58241758, 0.50537634, 0.64102564,\n",
       "          0.61333333, 0.61111111, 0.63551402, 0.59803922, 0.56989247]),\n",
       "   'train_precision': array([0.5974478 , 0.61319534, 0.59437751, 0.59713945, 0.59618008,\n",
       "          0.6012987 , 0.58659924, 0.58322581, 0.59764706, 0.58983051]),\n",
       "   'test_recall': array([0.08545455, 0.07818182, 0.09653916, 0.0856102 , 0.09107468,\n",
       "          0.08378871, 0.10018215, 0.12386157, 0.11111111, 0.09653916]),\n",
       "   'train_recall': array([0.10420882, 0.09591259, 0.08982399, 0.10135545, 0.08840785,\n",
       "          0.09366781, 0.09387012, 0.09144244, 0.1027716 , 0.10560388])}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=[\"C\",\"solver\",\"score\",\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for r in res_lr:\n",
    "    for k,v in r[1].items():\n",
    "      l = [r[0]]\n",
    "      l.append('lbfgs')\n",
    "      l.append(k)\n",
    "      for i in v:\n",
    "            l.append(i)\n",
    "      res_df.loc[cnt]=l  \n",
    "      cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.052246</td>\n",
       "      <td>0.966002</td>\n",
       "      <td>0.894012</td>\n",
       "      <td>0.938042</td>\n",
       "      <td>0.943671</td>\n",
       "      <td>1.080361</td>\n",
       "      <td>1.255824</td>\n",
       "      <td>1.321492</td>\n",
       "      <td>1.250191</td>\n",
       "      <td>1.076570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>0.028921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.816663</td>\n",
       "      <td>0.828836</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>0.793112</td>\n",
       "      <td>0.821504</td>\n",
       "      <td>0.823906</td>\n",
       "      <td>0.802030</td>\n",
       "      <td>0.814363</td>\n",
       "      <td>0.814002</td>\n",
       "      <td>0.828622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.818185</td>\n",
       "      <td>0.815972</td>\n",
       "      <td>0.814212</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>0.817236</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>0.817234</td>\n",
       "      <td>0.820073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935716</td>\n",
       "      <td>0.934890</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.938304</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.936409</td>\n",
       "      <td>0.937235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.937004</td>\n",
       "      <td>0.937331</td>\n",
       "      <td>0.937280</td>\n",
       "      <td>0.937319</td>\n",
       "      <td>0.936834</td>\n",
       "      <td>0.937188</td>\n",
       "      <td>0.937123</td>\n",
       "      <td>0.936979</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.937005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.576577</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.602410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.588364</td>\n",
       "      <td>0.585129</td>\n",
       "      <td>0.580581</td>\n",
       "      <td>0.563136</td>\n",
       "      <td>0.581270</td>\n",
       "      <td>0.576681</td>\n",
       "      <td>0.582017</td>\n",
       "      <td>0.574053</td>\n",
       "      <td>0.584882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>0.107468</td>\n",
       "      <td>0.091075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.108458</td>\n",
       "      <td>0.109852</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.111875</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.111066</td>\n",
       "      <td>0.096905</td>\n",
       "      <td>0.101153</td>\n",
       "      <td>0.095489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.916355</td>\n",
       "      <td>0.994372</td>\n",
       "      <td>0.965144</td>\n",
       "      <td>0.997334</td>\n",
       "      <td>1.056429</td>\n",
       "      <td>1.094785</td>\n",
       "      <td>1.161927</td>\n",
       "      <td>1.143637</td>\n",
       "      <td>1.094852</td>\n",
       "      <td>1.058884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.041537</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.029920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.817750</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.801580</td>\n",
       "      <td>0.798707</td>\n",
       "      <td>0.821025</td>\n",
       "      <td>0.825465</td>\n",
       "      <td>0.800724</td>\n",
       "      <td>0.817103</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.819321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.816876</td>\n",
       "      <td>0.819888</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.818774</td>\n",
       "      <td>0.815071</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0.815853</td>\n",
       "      <td>0.817820</td>\n",
       "      <td>0.815902</td>\n",
       "      <td>0.811873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935598</td>\n",
       "      <td>0.935716</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.936291</td>\n",
       "      <td>0.936527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936938</td>\n",
       "      <td>0.937279</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.936782</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.937202</td>\n",
       "      <td>0.936743</td>\n",
       "      <td>0.937123</td>\n",
       "      <td>0.937097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.554455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.568586</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.576433</td>\n",
       "      <td>0.563808</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.565804</td>\n",
       "      <td>0.571850</td>\n",
       "      <td>0.576759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.102004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.109875</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.109852</td>\n",
       "      <td>0.109043</td>\n",
       "      <td>0.112482</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.101760</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.109448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.089006</td>\n",
       "      <td>1.034839</td>\n",
       "      <td>1.059833</td>\n",
       "      <td>1.017789</td>\n",
       "      <td>1.035380</td>\n",
       "      <td>1.043287</td>\n",
       "      <td>1.095073</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>1.162853</td>\n",
       "      <td>1.013870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.029921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.819187</td>\n",
       "      <td>0.825605</td>\n",
       "      <td>0.804911</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.822584</td>\n",
       "      <td>0.826029</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>0.814903</td>\n",
       "      <td>0.808363</td>\n",
       "      <td>0.825398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.819594</td>\n",
       "      <td>0.815964</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.816141</td>\n",
       "      <td>0.817306</td>\n",
       "      <td>0.813815</td>\n",
       "      <td>0.818485</td>\n",
       "      <td>0.814661</td>\n",
       "      <td>0.811980</td>\n",
       "      <td>0.817742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935834</td>\n",
       "      <td>0.935952</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937950</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.937706</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.936763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936912</td>\n",
       "      <td>0.936977</td>\n",
       "      <td>0.936755</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.936913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.563107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.567539</td>\n",
       "      <td>0.568507</td>\n",
       "      <td>0.561975</td>\n",
       "      <td>0.577160</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.568228</td>\n",
       "      <td>0.566703</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.568565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.096364</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.105647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.109672</td>\n",
       "      <td>0.112505</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>0.113494</td>\n",
       "      <td>0.106211</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.103985</td>\n",
       "      <td>0.105199</td>\n",
       "      <td>0.110055</td>\n",
       "      <td>0.109043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.996058</td>\n",
       "      <td>1.088600</td>\n",
       "      <td>1.223107</td>\n",
       "      <td>1.152949</td>\n",
       "      <td>1.168881</td>\n",
       "      <td>1.052187</td>\n",
       "      <td>1.064985</td>\n",
       "      <td>1.049221</td>\n",
       "      <td>1.024825</td>\n",
       "      <td>1.161333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.044879</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.034909</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.040891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.825027</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.794907</td>\n",
       "      <td>0.822178</td>\n",
       "      <td>0.826330</td>\n",
       "      <td>0.801134</td>\n",
       "      <td>0.817659</td>\n",
       "      <td>0.811657</td>\n",
       "      <td>0.823738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.816485</td>\n",
       "      <td>0.815362</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.814526</td>\n",
       "      <td>0.816648</td>\n",
       "      <td>0.817663</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.816794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.937117</td>\n",
       "      <td>0.936055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936833</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.937280</td>\n",
       "      <td>0.937162</td>\n",
       "      <td>0.936690</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.936809</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.936861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.495146</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.565495</td>\n",
       "      <td>0.580874</td>\n",
       "      <td>0.582636</td>\n",
       "      <td>0.581066</td>\n",
       "      <td>0.559662</td>\n",
       "      <td>0.559799</td>\n",
       "      <td>0.584706</td>\n",
       "      <td>0.570115</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.568330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>0.125683</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.129326</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.096539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.107446</td>\n",
       "      <td>0.099555</td>\n",
       "      <td>0.112685</td>\n",
       "      <td>0.108032</td>\n",
       "      <td>0.107222</td>\n",
       "      <td>0.112685</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>0.100344</td>\n",
       "      <td>0.114910</td>\n",
       "      <td>0.106008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.074472</td>\n",
       "      <td>1.027870</td>\n",
       "      <td>1.072591</td>\n",
       "      <td>1.066103</td>\n",
       "      <td>1.036472</td>\n",
       "      <td>1.077780</td>\n",
       "      <td>1.087669</td>\n",
       "      <td>1.097147</td>\n",
       "      <td>1.033271</td>\n",
       "      <td>1.038320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.031922</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.034913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.813293</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.804245</td>\n",
       "      <td>0.796903</td>\n",
       "      <td>0.823082</td>\n",
       "      <td>0.827771</td>\n",
       "      <td>0.805650</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.810559</td>\n",
       "      <td>0.820647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.812554</td>\n",
       "      <td>0.812093</td>\n",
       "      <td>0.819110</td>\n",
       "      <td>0.817118</td>\n",
       "      <td>0.817198</td>\n",
       "      <td>0.815359</td>\n",
       "      <td>0.819829</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.813643</td>\n",
       "      <td>0.812968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.936188</td>\n",
       "      <td>0.935952</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.936763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.937423</td>\n",
       "      <td>0.937515</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937345</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>0.937005</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.937385</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.569892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.597448</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.594378</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.596180</td>\n",
       "      <td>0.601299</td>\n",
       "      <td>0.586599</td>\n",
       "      <td>0.583226</td>\n",
       "      <td>0.597647</td>\n",
       "      <td>0.589831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.096539</td>\n",
       "      <td>0.085610</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.083789</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.096539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.104209</td>\n",
       "      <td>0.095913</td>\n",
       "      <td>0.089824</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.088408</td>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.093870</td>\n",
       "      <td>0.091442</td>\n",
       "      <td>0.102772</td>\n",
       "      <td>0.105604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C solver            score  score_val0  score_val1  score_val2  \\\n",
       "0   1.00  lbfgs         fit_time    1.052246    0.966002    0.894012   \n",
       "1   1.00  lbfgs       score_time    0.027925    0.025930    0.029918   \n",
       "2   1.00  lbfgs     test_roc_auc    0.816663    0.828836    0.801971   \n",
       "3   1.00  lbfgs    train_roc_auc    0.815536    0.818185    0.815972   \n",
       "4   1.00  lbfgs    test_accuracy    0.935716    0.934890    0.936770   \n",
       "5   1.00  lbfgs   train_accuracy    0.937004    0.937331    0.937280   \n",
       "6   1.00  lbfgs   test_precision    0.528736    0.489130    0.554622   \n",
       "7   1.00  lbfgs  train_precision    0.569106    0.588364    0.585129   \n",
       "8   1.00  lbfgs      test_recall    0.083636    0.081818    0.120219   \n",
       "9   1.00  lbfgs     train_recall    0.113314    0.108458    0.109852   \n",
       "10  0.80  lbfgs         fit_time    0.916355    0.994372    0.965144   \n",
       "11  0.80  lbfgs       score_time    0.030918    0.029408    0.026926   \n",
       "12  0.80  lbfgs     test_roc_auc    0.817750    0.829987    0.801580   \n",
       "13  0.80  lbfgs    train_roc_auc    0.816876    0.819888    0.815562   \n",
       "14  0.80  lbfgs    test_accuracy    0.935598    0.935716    0.937242   \n",
       "15  0.80  lbfgs   train_accuracy    0.936938    0.937279    0.937096   \n",
       "16  0.80  lbfgs   test_precision    0.522727    0.530864    0.573913   \n",
       "17  0.80  lbfgs  train_precision    0.568586    0.591173    0.576433   \n",
       "18  0.80  lbfgs      test_recall    0.083636    0.078182    0.120219   \n",
       "19  0.80  lbfgs     train_recall    0.109875    0.102995    0.109852   \n",
       "20  0.50  lbfgs         fit_time    1.089006    1.034839    1.059833   \n",
       "21  0.50  lbfgs       score_time    0.034906    0.029275    0.029920   \n",
       "22  0.50  lbfgs     test_roc_auc    0.819187    0.825605    0.804911   \n",
       "23  0.50  lbfgs    train_roc_auc    0.819594    0.815964    0.819149   \n",
       "24  0.50  lbfgs    test_accuracy    0.935834    0.935952    0.936888   \n",
       "25  0.50  lbfgs   train_accuracy    0.936912    0.936977    0.936755   \n",
       "26  0.50  lbfgs   test_precision    0.534884    0.535354    0.561404   \n",
       "27  0.50  lbfgs  train_precision    0.567539    0.568507    0.561975   \n",
       "28  0.50  lbfgs      test_recall    0.083636    0.096364    0.116576   \n",
       "29  0.50  lbfgs     train_recall    0.109672    0.112505    0.108234   \n",
       "30  0.30  lbfgs         fit_time    0.996058    1.088600    1.223107   \n",
       "31  0.30  lbfgs       score_time    0.028923    0.044879    0.035895   \n",
       "32  0.30  lbfgs     test_roc_auc    0.816906    0.825027    0.800228   \n",
       "33  0.30  lbfgs    train_roc_auc    0.816485    0.815362    0.813512   \n",
       "34  0.30  lbfgs    test_accuracy    0.935362    0.935362    0.937242   \n",
       "35  0.30  lbfgs   train_accuracy    0.936833    0.937017    0.937280   \n",
       "36  0.30  lbfgs   test_precision    0.511905    0.510870    0.570248   \n",
       "37  0.30  lbfgs  train_precision    0.565495    0.580874    0.582636   \n",
       "38  0.30  lbfgs      test_recall    0.078182    0.085455    0.125683   \n",
       "39  0.30  lbfgs     train_recall    0.107446    0.099555    0.112685   \n",
       "40  0.01  lbfgs         fit_time    1.074472    1.027870    1.072591   \n",
       "41  0.01  lbfgs       score_time    0.032912    0.033908    0.036902   \n",
       "42  0.01  lbfgs     test_roc_auc    0.813293    0.822034    0.804245   \n",
       "43  0.01  lbfgs    train_roc_auc    0.812554    0.812093    0.819110   \n",
       "44  0.01  lbfgs    test_accuracy    0.936188    0.935952    0.937006   \n",
       "45  0.01  lbfgs   train_accuracy    0.937423    0.937515    0.937057   \n",
       "46  0.01  lbfgs   test_precision    0.552941    0.544304    0.582418   \n",
       "47  0.01  lbfgs  train_precision    0.597448    0.613195    0.594378   \n",
       "48  0.01  lbfgs      test_recall    0.085455    0.078182    0.096539   \n",
       "49  0.01  lbfgs     train_recall    0.104209    0.095913    0.089824   \n",
       "\n",
       "    score_val3  score_val4  score_val5  score_val6  score_val7  score_val8  \\\n",
       "0     0.938042    0.943671    1.080361    1.255824    1.321492    1.250191   \n",
       "1     0.025931    0.027925    0.032919    0.027926    0.028924    0.033909   \n",
       "2     0.793112    0.821504    0.823906    0.802030    0.814363    0.814002   \n",
       "3     0.814212    0.815690    0.812780    0.817236    0.815646    0.817234   \n",
       "4     0.935472    0.938304    0.937478    0.937235    0.938296    0.936409   \n",
       "5     0.937319    0.936834    0.937188    0.937123    0.936979    0.936900   \n",
       "6     0.509091    0.622642    0.606742    0.576577    0.625000    0.546296   \n",
       "7     0.580581    0.563136    0.581270    0.576681    0.582017    0.574053   \n",
       "8     0.102004    0.120219    0.098361    0.116576    0.118397    0.107468   \n",
       "9     0.117338    0.111875    0.109245    0.111066    0.096905    0.101153   \n",
       "10    0.997334    1.056429    1.094785    1.161927    1.143637    1.094852   \n",
       "11    0.031423    0.034906    0.041537    0.042886    0.034908    0.030917   \n",
       "12    0.798707    0.821025    0.825465    0.800724    0.817103    0.812540   \n",
       "13    0.818774    0.815071    0.813477    0.815853    0.817820    0.815902   \n",
       "14    0.935590    0.937714    0.936888    0.937235    0.938178    0.936291   \n",
       "15    0.936808    0.936782    0.937017    0.937202    0.936743    0.937123   \n",
       "16    0.513761    0.594595    0.583333    0.575221    0.605042    0.535433   \n",
       "17    0.563808    0.560484    0.576667    0.575248    0.565804    0.571850   \n",
       "18    0.102004    0.120219    0.089253    0.118397    0.131148    0.123862   \n",
       "19    0.109043    0.112482    0.104997    0.117540    0.101760    0.117540   \n",
       "20    1.017789    1.035380    1.043287    1.095073    0.995363    1.162853   \n",
       "21    0.029921    0.027926    0.030917    0.030921    0.030918    0.035905   \n",
       "22    0.794677    0.822584    0.826029    0.803381    0.814903    0.808363   \n",
       "23    0.816141    0.817306    0.813815    0.818485    0.814661    0.811980   \n",
       "24    0.935826    0.937950    0.937478    0.937471    0.937706    0.938296   \n",
       "25    0.937175    0.936768    0.936965    0.936795    0.936717    0.937333   \n",
       "26    0.522936    0.616162    0.604396    0.590476    0.585366    0.622642   \n",
       "27    0.577160    0.563910    0.568228    0.566703    0.562162    0.587473   \n",
       "28    0.103825    0.111111    0.100182    0.112933    0.131148    0.120219   \n",
       "29    0.113494    0.106211    0.112887    0.103985    0.105199    0.110055   \n",
       "30    1.152949    1.168881    1.052187    1.064985    1.049221    1.024825   \n",
       "31    0.038896    0.030921    0.032912    0.033910    0.034909    0.032421   \n",
       "32    0.794907    0.822178    0.826330    0.801134    0.817659    0.811657   \n",
       "33    0.815762    0.816275    0.814526    0.816648    0.817663    0.814895   \n",
       "34    0.935119    0.937714    0.937596    0.937588    0.938296    0.937117   \n",
       "35    0.937162    0.936690    0.936768    0.937097    0.936809    0.937097   \n",
       "36    0.495146    0.603960    0.606383    0.598039    0.612069    0.566667   \n",
       "37    0.581066    0.559662    0.559799    0.584706    0.570115    0.572581   \n",
       "38    0.092896    0.111111    0.103825    0.111111    0.129326    0.123862   \n",
       "39    0.108032    0.107222    0.112685    0.100546    0.100344    0.114910   \n",
       "40    1.066103    1.036472    1.077780    1.087669    1.097147    1.033271   \n",
       "41    0.033911    0.035903    0.031922    0.029920    0.033384    0.030917   \n",
       "42    0.796903    0.823082    0.827771    0.805650    0.818831    0.810559   \n",
       "43    0.817118    0.817198    0.815359    0.819829    0.819380    0.813643   \n",
       "44    0.935354    0.937832    0.937242    0.937588    0.938650    0.937588   \n",
       "45    0.937345    0.937057    0.937253    0.937005    0.936900    0.937385   \n",
       "46    0.505376    0.641026    0.613333    0.611111    0.635514    0.598039   \n",
       "47    0.597139    0.596180    0.601299    0.586599    0.583226    0.597647   \n",
       "48    0.085610    0.091075    0.083789    0.100182    0.123862    0.111111   \n",
       "49    0.101355    0.088408    0.093668    0.093870    0.091442    0.102772   \n",
       "\n",
       "    score_val9  \n",
       "0     1.076570  \n",
       "1     0.028921  \n",
       "2     0.828622  \n",
       "3     0.820073  \n",
       "4     0.937235  \n",
       "5     0.937005  \n",
       "6     0.602410  \n",
       "7     0.584882  \n",
       "8     0.091075  \n",
       "9     0.095489  \n",
       "10    1.058884  \n",
       "11    0.029920  \n",
       "12    0.819321  \n",
       "13    0.811873  \n",
       "14    0.936527  \n",
       "15    0.937097  \n",
       "16    0.554455  \n",
       "17    0.576759  \n",
       "18    0.102004  \n",
       "19    0.109448  \n",
       "20    1.013870  \n",
       "21    0.029921  \n",
       "22    0.825398  \n",
       "23    0.817742  \n",
       "24    0.936763  \n",
       "25    0.936913  \n",
       "26    0.563107  \n",
       "27    0.568565  \n",
       "28    0.105647  \n",
       "29    0.109043  \n",
       "30    1.161333  \n",
       "31    0.040891  \n",
       "32    0.823738  \n",
       "33    0.816794  \n",
       "34    0.936055  \n",
       "35    0.936861  \n",
       "36    0.535354  \n",
       "37    0.568330  \n",
       "38    0.096539  \n",
       "39    0.106008  \n",
       "40    1.038320  \n",
       "41    0.034913  \n",
       "42    0.820647  \n",
       "43    0.812968  \n",
       "44    0.936763  \n",
       "45    0.937294  \n",
       "46    0.569892  \n",
       "47    0.589831  \n",
       "48    0.096539  \n",
       "49    0.105604  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['average'] = res_df[[\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\"]].mean(numeric_only=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.052246</td>\n",
       "      <td>0.966002</td>\n",
       "      <td>0.894012</td>\n",
       "      <td>0.938042</td>\n",
       "      <td>0.943671</td>\n",
       "      <td>1.080361</td>\n",
       "      <td>1.255824</td>\n",
       "      <td>1.321492</td>\n",
       "      <td>1.250191</td>\n",
       "      <td>1.076570</td>\n",
       "      <td>1.077841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>0.028921</td>\n",
       "      <td>0.029023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.816663</td>\n",
       "      <td>0.828836</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>0.793112</td>\n",
       "      <td>0.821504</td>\n",
       "      <td>0.823906</td>\n",
       "      <td>0.802030</td>\n",
       "      <td>0.814363</td>\n",
       "      <td>0.814002</td>\n",
       "      <td>0.828622</td>\n",
       "      <td>0.814501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.818185</td>\n",
       "      <td>0.815972</td>\n",
       "      <td>0.814212</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>0.817236</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>0.817234</td>\n",
       "      <td>0.820073</td>\n",
       "      <td>0.816256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935716</td>\n",
       "      <td>0.934890</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.938304</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.936409</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.936780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.937004</td>\n",
       "      <td>0.937331</td>\n",
       "      <td>0.937280</td>\n",
       "      <td>0.937319</td>\n",
       "      <td>0.936834</td>\n",
       "      <td>0.937188</td>\n",
       "      <td>0.937123</td>\n",
       "      <td>0.936979</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.937005</td>\n",
       "      <td>0.937096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.576577</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.566124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.588364</td>\n",
       "      <td>0.585129</td>\n",
       "      <td>0.580581</td>\n",
       "      <td>0.563136</td>\n",
       "      <td>0.581270</td>\n",
       "      <td>0.576681</td>\n",
       "      <td>0.582017</td>\n",
       "      <td>0.574053</td>\n",
       "      <td>0.584882</td>\n",
       "      <td>0.578522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>0.107468</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.103977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.108458</td>\n",
       "      <td>0.109852</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.111875</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.111066</td>\n",
       "      <td>0.096905</td>\n",
       "      <td>0.101153</td>\n",
       "      <td>0.095489</td>\n",
       "      <td>0.107470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.916355</td>\n",
       "      <td>0.994372</td>\n",
       "      <td>0.965144</td>\n",
       "      <td>0.997334</td>\n",
       "      <td>1.056429</td>\n",
       "      <td>1.094785</td>\n",
       "      <td>1.161927</td>\n",
       "      <td>1.143637</td>\n",
       "      <td>1.094852</td>\n",
       "      <td>1.058884</td>\n",
       "      <td>1.048372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.041537</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.033375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.817750</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.801580</td>\n",
       "      <td>0.798707</td>\n",
       "      <td>0.821025</td>\n",
       "      <td>0.825465</td>\n",
       "      <td>0.800724</td>\n",
       "      <td>0.817103</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.819321</td>\n",
       "      <td>0.814420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.816876</td>\n",
       "      <td>0.819888</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.818774</td>\n",
       "      <td>0.815071</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0.815853</td>\n",
       "      <td>0.817820</td>\n",
       "      <td>0.815902</td>\n",
       "      <td>0.811873</td>\n",
       "      <td>0.816110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935598</td>\n",
       "      <td>0.935716</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.936291</td>\n",
       "      <td>0.936527</td>\n",
       "      <td>0.936698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936938</td>\n",
       "      <td>0.937279</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.936808</td>\n",
       "      <td>0.936782</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.937202</td>\n",
       "      <td>0.936743</td>\n",
       "      <td>0.937123</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.937008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.558935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.568586</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.576433</td>\n",
       "      <td>0.563808</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.565804</td>\n",
       "      <td>0.571850</td>\n",
       "      <td>0.576759</td>\n",
       "      <td>0.572681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.106892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.109875</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.109852</td>\n",
       "      <td>0.109043</td>\n",
       "      <td>0.112482</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.101760</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.109448</td>\n",
       "      <td>0.109553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.089006</td>\n",
       "      <td>1.034839</td>\n",
       "      <td>1.059833</td>\n",
       "      <td>1.017789</td>\n",
       "      <td>1.035380</td>\n",
       "      <td>1.043287</td>\n",
       "      <td>1.095073</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>1.162853</td>\n",
       "      <td>1.013870</td>\n",
       "      <td>1.054729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>0.031053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.819187</td>\n",
       "      <td>0.825605</td>\n",
       "      <td>0.804911</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.822584</td>\n",
       "      <td>0.826029</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>0.814903</td>\n",
       "      <td>0.808363</td>\n",
       "      <td>0.825398</td>\n",
       "      <td>0.814504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.819594</td>\n",
       "      <td>0.815964</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.816141</td>\n",
       "      <td>0.817306</td>\n",
       "      <td>0.813815</td>\n",
       "      <td>0.818485</td>\n",
       "      <td>0.814661</td>\n",
       "      <td>0.811980</td>\n",
       "      <td>0.817742</td>\n",
       "      <td>0.816484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935834</td>\n",
       "      <td>0.935952</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937950</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.937706</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.936763</td>\n",
       "      <td>0.937016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936912</td>\n",
       "      <td>0.936977</td>\n",
       "      <td>0.936755</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>0.937333</td>\n",
       "      <td>0.936913</td>\n",
       "      <td>0.936931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.573672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.567539</td>\n",
       "      <td>0.568507</td>\n",
       "      <td>0.561975</td>\n",
       "      <td>0.577160</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.568228</td>\n",
       "      <td>0.566703</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.568565</td>\n",
       "      <td>0.569222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.083636</td>\n",
       "      <td>0.096364</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.108164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.109672</td>\n",
       "      <td>0.112505</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>0.113494</td>\n",
       "      <td>0.106211</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.103985</td>\n",
       "      <td>0.105199</td>\n",
       "      <td>0.110055</td>\n",
       "      <td>0.109043</td>\n",
       "      <td>0.109129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.996058</td>\n",
       "      <td>1.088600</td>\n",
       "      <td>1.223107</td>\n",
       "      <td>1.152949</td>\n",
       "      <td>1.168881</td>\n",
       "      <td>1.052187</td>\n",
       "      <td>1.064985</td>\n",
       "      <td>1.049221</td>\n",
       "      <td>1.024825</td>\n",
       "      <td>1.161333</td>\n",
       "      <td>1.098215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.044879</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.034909</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>0.035456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.825027</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.794907</td>\n",
       "      <td>0.822178</td>\n",
       "      <td>0.826330</td>\n",
       "      <td>0.801134</td>\n",
       "      <td>0.817659</td>\n",
       "      <td>0.811657</td>\n",
       "      <td>0.823738</td>\n",
       "      <td>0.813976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.816485</td>\n",
       "      <td>0.815362</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.814526</td>\n",
       "      <td>0.816648</td>\n",
       "      <td>0.817663</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.815792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>0.937714</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.938296</td>\n",
       "      <td>0.937117</td>\n",
       "      <td>0.936055</td>\n",
       "      <td>0.936745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.936833</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.937280</td>\n",
       "      <td>0.937162</td>\n",
       "      <td>0.936690</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.936809</td>\n",
       "      <td>0.937097</td>\n",
       "      <td>0.936861</td>\n",
       "      <td>0.936961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.495146</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.561064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.565495</td>\n",
       "      <td>0.580874</td>\n",
       "      <td>0.582636</td>\n",
       "      <td>0.581066</td>\n",
       "      <td>0.559662</td>\n",
       "      <td>0.559799</td>\n",
       "      <td>0.584706</td>\n",
       "      <td>0.570115</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.568330</td>\n",
       "      <td>0.572526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>0.125683</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.129326</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.096539</td>\n",
       "      <td>0.105799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.107446</td>\n",
       "      <td>0.099555</td>\n",
       "      <td>0.112685</td>\n",
       "      <td>0.108032</td>\n",
       "      <td>0.107222</td>\n",
       "      <td>0.112685</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>0.100344</td>\n",
       "      <td>0.114910</td>\n",
       "      <td>0.106008</td>\n",
       "      <td>0.106943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.074472</td>\n",
       "      <td>1.027870</td>\n",
       "      <td>1.072591</td>\n",
       "      <td>1.066103</td>\n",
       "      <td>1.036472</td>\n",
       "      <td>1.077780</td>\n",
       "      <td>1.087669</td>\n",
       "      <td>1.097147</td>\n",
       "      <td>1.033271</td>\n",
       "      <td>1.038320</td>\n",
       "      <td>1.061169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.031922</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.033459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.813293</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.804245</td>\n",
       "      <td>0.796903</td>\n",
       "      <td>0.823082</td>\n",
       "      <td>0.827771</td>\n",
       "      <td>0.805650</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.810559</td>\n",
       "      <td>0.820647</td>\n",
       "      <td>0.814301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.812554</td>\n",
       "      <td>0.812093</td>\n",
       "      <td>0.819110</td>\n",
       "      <td>0.817118</td>\n",
       "      <td>0.817198</td>\n",
       "      <td>0.815359</td>\n",
       "      <td>0.819829</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.813643</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.815925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.936188</td>\n",
       "      <td>0.935952</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.936763</td>\n",
       "      <td>0.937016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.937423</td>\n",
       "      <td>0.937515</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937345</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>0.937005</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>0.937385</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.937223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.585395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.597448</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.594378</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.596180</td>\n",
       "      <td>0.601299</td>\n",
       "      <td>0.586599</td>\n",
       "      <td>0.583226</td>\n",
       "      <td>0.597647</td>\n",
       "      <td>0.589831</td>\n",
       "      <td>0.595694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.096539</td>\n",
       "      <td>0.085610</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>0.083789</td>\n",
       "      <td>0.100182</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.096539</td>\n",
       "      <td>0.095234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.104209</td>\n",
       "      <td>0.095913</td>\n",
       "      <td>0.089824</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.088408</td>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.093870</td>\n",
       "      <td>0.091442</td>\n",
       "      <td>0.102772</td>\n",
       "      <td>0.105604</td>\n",
       "      <td>0.096706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C solver            score  score_val0  score_val1  score_val2  \\\n",
       "0   1.00  lbfgs         fit_time    1.052246    0.966002    0.894012   \n",
       "1   1.00  lbfgs       score_time    0.027925    0.025930    0.029918   \n",
       "2   1.00  lbfgs     test_roc_auc    0.816663    0.828836    0.801971   \n",
       "3   1.00  lbfgs    train_roc_auc    0.815536    0.818185    0.815972   \n",
       "4   1.00  lbfgs    test_accuracy    0.935716    0.934890    0.936770   \n",
       "5   1.00  lbfgs   train_accuracy    0.937004    0.937331    0.937280   \n",
       "6   1.00  lbfgs   test_precision    0.528736    0.489130    0.554622   \n",
       "7   1.00  lbfgs  train_precision    0.569106    0.588364    0.585129   \n",
       "8   1.00  lbfgs      test_recall    0.083636    0.081818    0.120219   \n",
       "9   1.00  lbfgs     train_recall    0.113314    0.108458    0.109852   \n",
       "10  0.80  lbfgs         fit_time    0.916355    0.994372    0.965144   \n",
       "11  0.80  lbfgs       score_time    0.030918    0.029408    0.026926   \n",
       "12  0.80  lbfgs     test_roc_auc    0.817750    0.829987    0.801580   \n",
       "13  0.80  lbfgs    train_roc_auc    0.816876    0.819888    0.815562   \n",
       "14  0.80  lbfgs    test_accuracy    0.935598    0.935716    0.937242   \n",
       "15  0.80  lbfgs   train_accuracy    0.936938    0.937279    0.937096   \n",
       "16  0.80  lbfgs   test_precision    0.522727    0.530864    0.573913   \n",
       "17  0.80  lbfgs  train_precision    0.568586    0.591173    0.576433   \n",
       "18  0.80  lbfgs      test_recall    0.083636    0.078182    0.120219   \n",
       "19  0.80  lbfgs     train_recall    0.109875    0.102995    0.109852   \n",
       "20  0.50  lbfgs         fit_time    1.089006    1.034839    1.059833   \n",
       "21  0.50  lbfgs       score_time    0.034906    0.029275    0.029920   \n",
       "22  0.50  lbfgs     test_roc_auc    0.819187    0.825605    0.804911   \n",
       "23  0.50  lbfgs    train_roc_auc    0.819594    0.815964    0.819149   \n",
       "24  0.50  lbfgs    test_accuracy    0.935834    0.935952    0.936888   \n",
       "25  0.50  lbfgs   train_accuracy    0.936912    0.936977    0.936755   \n",
       "26  0.50  lbfgs   test_precision    0.534884    0.535354    0.561404   \n",
       "27  0.50  lbfgs  train_precision    0.567539    0.568507    0.561975   \n",
       "28  0.50  lbfgs      test_recall    0.083636    0.096364    0.116576   \n",
       "29  0.50  lbfgs     train_recall    0.109672    0.112505    0.108234   \n",
       "30  0.30  lbfgs         fit_time    0.996058    1.088600    1.223107   \n",
       "31  0.30  lbfgs       score_time    0.028923    0.044879    0.035895   \n",
       "32  0.30  lbfgs     test_roc_auc    0.816906    0.825027    0.800228   \n",
       "33  0.30  lbfgs    train_roc_auc    0.816485    0.815362    0.813512   \n",
       "34  0.30  lbfgs    test_accuracy    0.935362    0.935362    0.937242   \n",
       "35  0.30  lbfgs   train_accuracy    0.936833    0.937017    0.937280   \n",
       "36  0.30  lbfgs   test_precision    0.511905    0.510870    0.570248   \n",
       "37  0.30  lbfgs  train_precision    0.565495    0.580874    0.582636   \n",
       "38  0.30  lbfgs      test_recall    0.078182    0.085455    0.125683   \n",
       "39  0.30  lbfgs     train_recall    0.107446    0.099555    0.112685   \n",
       "40  0.01  lbfgs         fit_time    1.074472    1.027870    1.072591   \n",
       "41  0.01  lbfgs       score_time    0.032912    0.033908    0.036902   \n",
       "42  0.01  lbfgs     test_roc_auc    0.813293    0.822034    0.804245   \n",
       "43  0.01  lbfgs    train_roc_auc    0.812554    0.812093    0.819110   \n",
       "44  0.01  lbfgs    test_accuracy    0.936188    0.935952    0.937006   \n",
       "45  0.01  lbfgs   train_accuracy    0.937423    0.937515    0.937057   \n",
       "46  0.01  lbfgs   test_precision    0.552941    0.544304    0.582418   \n",
       "47  0.01  lbfgs  train_precision    0.597448    0.613195    0.594378   \n",
       "48  0.01  lbfgs      test_recall    0.085455    0.078182    0.096539   \n",
       "49  0.01  lbfgs     train_recall    0.104209    0.095913    0.089824   \n",
       "\n",
       "    score_val3  score_val4  score_val5  score_val6  score_val7  score_val8  \\\n",
       "0     0.938042    0.943671    1.080361    1.255824    1.321492    1.250191   \n",
       "1     0.025931    0.027925    0.032919    0.027926    0.028924    0.033909   \n",
       "2     0.793112    0.821504    0.823906    0.802030    0.814363    0.814002   \n",
       "3     0.814212    0.815690    0.812780    0.817236    0.815646    0.817234   \n",
       "4     0.935472    0.938304    0.937478    0.937235    0.938296    0.936409   \n",
       "5     0.937319    0.936834    0.937188    0.937123    0.936979    0.936900   \n",
       "6     0.509091    0.622642    0.606742    0.576577    0.625000    0.546296   \n",
       "7     0.580581    0.563136    0.581270    0.576681    0.582017    0.574053   \n",
       "8     0.102004    0.120219    0.098361    0.116576    0.118397    0.107468   \n",
       "9     0.117338    0.111875    0.109245    0.111066    0.096905    0.101153   \n",
       "10    0.997334    1.056429    1.094785    1.161927    1.143637    1.094852   \n",
       "11    0.031423    0.034906    0.041537    0.042886    0.034908    0.030917   \n",
       "12    0.798707    0.821025    0.825465    0.800724    0.817103    0.812540   \n",
       "13    0.818774    0.815071    0.813477    0.815853    0.817820    0.815902   \n",
       "14    0.935590    0.937714    0.936888    0.937235    0.938178    0.936291   \n",
       "15    0.936808    0.936782    0.937017    0.937202    0.936743    0.937123   \n",
       "16    0.513761    0.594595    0.583333    0.575221    0.605042    0.535433   \n",
       "17    0.563808    0.560484    0.576667    0.575248    0.565804    0.571850   \n",
       "18    0.102004    0.120219    0.089253    0.118397    0.131148    0.123862   \n",
       "19    0.109043    0.112482    0.104997    0.117540    0.101760    0.117540   \n",
       "20    1.017789    1.035380    1.043287    1.095073    0.995363    1.162853   \n",
       "21    0.029921    0.027926    0.030917    0.030921    0.030918    0.035905   \n",
       "22    0.794677    0.822584    0.826029    0.803381    0.814903    0.808363   \n",
       "23    0.816141    0.817306    0.813815    0.818485    0.814661    0.811980   \n",
       "24    0.935826    0.937950    0.937478    0.937471    0.937706    0.938296   \n",
       "25    0.937175    0.936768    0.936965    0.936795    0.936717    0.937333   \n",
       "26    0.522936    0.616162    0.604396    0.590476    0.585366    0.622642   \n",
       "27    0.577160    0.563910    0.568228    0.566703    0.562162    0.587473   \n",
       "28    0.103825    0.111111    0.100182    0.112933    0.131148    0.120219   \n",
       "29    0.113494    0.106211    0.112887    0.103985    0.105199    0.110055   \n",
       "30    1.152949    1.168881    1.052187    1.064985    1.049221    1.024825   \n",
       "31    0.038896    0.030921    0.032912    0.033910    0.034909    0.032421   \n",
       "32    0.794907    0.822178    0.826330    0.801134    0.817659    0.811657   \n",
       "33    0.815762    0.816275    0.814526    0.816648    0.817663    0.814895   \n",
       "34    0.935119    0.937714    0.937596    0.937588    0.938296    0.937117   \n",
       "35    0.937162    0.936690    0.936768    0.937097    0.936809    0.937097   \n",
       "36    0.495146    0.603960    0.606383    0.598039    0.612069    0.566667   \n",
       "37    0.581066    0.559662    0.559799    0.584706    0.570115    0.572581   \n",
       "38    0.092896    0.111111    0.103825    0.111111    0.129326    0.123862   \n",
       "39    0.108032    0.107222    0.112685    0.100546    0.100344    0.114910   \n",
       "40    1.066103    1.036472    1.077780    1.087669    1.097147    1.033271   \n",
       "41    0.033911    0.035903    0.031922    0.029920    0.033384    0.030917   \n",
       "42    0.796903    0.823082    0.827771    0.805650    0.818831    0.810559   \n",
       "43    0.817118    0.817198    0.815359    0.819829    0.819380    0.813643   \n",
       "44    0.935354    0.937832    0.937242    0.937588    0.938650    0.937588   \n",
       "45    0.937345    0.937057    0.937253    0.937005    0.936900    0.937385   \n",
       "46    0.505376    0.641026    0.613333    0.611111    0.635514    0.598039   \n",
       "47    0.597139    0.596180    0.601299    0.586599    0.583226    0.597647   \n",
       "48    0.085610    0.091075    0.083789    0.100182    0.123862    0.111111   \n",
       "49    0.101355    0.088408    0.093668    0.093870    0.091442    0.102772   \n",
       "\n",
       "    score_val9   average  \n",
       "0     1.076570  1.077841  \n",
       "1     0.028921  0.029023  \n",
       "2     0.828622  0.814501  \n",
       "3     0.820073  0.816256  \n",
       "4     0.937235  0.936780  \n",
       "5     0.937005  0.937096  \n",
       "6     0.602410  0.566124  \n",
       "7     0.584882  0.578522  \n",
       "8     0.091075  0.103977  \n",
       "9     0.095489  0.107470  \n",
       "10    1.058884  1.048372  \n",
       "11    0.029920  0.033375  \n",
       "12    0.819321  0.814420  \n",
       "13    0.811873  0.816110  \n",
       "14    0.936527  0.936698  \n",
       "15    0.937097  0.937008  \n",
       "16    0.554455  0.558935  \n",
       "17    0.576759  0.572681  \n",
       "18    0.102004  0.106892  \n",
       "19    0.109448  0.109553  \n",
       "20    1.013870  1.054729  \n",
       "21    0.029921  0.031053  \n",
       "22    0.825398  0.814504  \n",
       "23    0.817742  0.816484  \n",
       "24    0.936763  0.937016  \n",
       "25    0.936913  0.936931  \n",
       "26    0.563107  0.573672  \n",
       "27    0.568565  0.569222  \n",
       "28    0.105647  0.108164  \n",
       "29    0.109043  0.109129  \n",
       "30    1.161333  1.098215  \n",
       "31    0.040891  0.035456  \n",
       "32    0.823738  0.813976  \n",
       "33    0.816794  0.815792  \n",
       "34    0.936055  0.936745  \n",
       "35    0.936861  0.936961  \n",
       "36    0.535354  0.561064  \n",
       "37    0.568330  0.572526  \n",
       "38    0.096539  0.105799  \n",
       "39    0.106008  0.106943  \n",
       "40    1.038320  1.061169  \n",
       "41    0.034913  0.033459  \n",
       "42    0.820647  0.814301  \n",
       "43    0.812968  0.815925  \n",
       "44    0.936763  0.937016  \n",
       "45    0.937294  0.937223  \n",
       "46    0.569892  0.585395  \n",
       "47    0.589831  0.595694  \n",
       "48    0.096539  0.095234  \n",
       "49    0.105604  0.096706  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RF:  10 sqrt\n",
      "Running RF:  10 log2\n",
      "Running RF:  10 None\n",
      "Running RF:  55 sqrt\n",
      "Running RF:  55 log2\n",
      "Running RF:  55 None\n",
      "Running RF:  100 sqrt\n",
      "Running RF:  100 log2\n",
      "Running RF:  100 None\n",
      "Running RF:  200 sqrt\n",
      "Running RF:  200 log2\n",
      "Running RF:  200 None\n",
      "Running RF:  1000 sqrt\n",
      "Running RF:  1000 log2\n",
      "Running RF:  1000 None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "res_rf = []\n",
    "for t in list(map(int,np.linspace(10, 100, num=3)))+list(map(int,np.linspace(200, 1000, num=2))):\n",
    "    for f in [\"sqrt\",\"log2\",None]:\n",
    "      print('Running RF: ', t, f)\n",
    "      rf = RandomForestClassifier(n_estimators = t, max_features = f)\n",
    "      scores = [t, f, cross_validate(rf, tr[cols], tr['HighUtilizationY2'], scoring=['roc_auc','accuracy','precision','recall'], cv=10)]\n",
    "      res_rf.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([1.08280468, 0.98315859, 1.05116796, 0.96878433, 1.07296205,\n",
       "          1.25250459, 1.0642283 , 1.0701232 , 1.02904677, 1.02408957]),\n",
       "   'score_time': array([0.11467409, 0.09915996, 0.10468006, 0.10599256, 0.10172772,\n",
       "          0.10073447, 0.09719014, 0.10925341, 0.11868382, 0.11089134]),\n",
       "   'test_roc_auc': array([0.7291901 , 0.7518441 , 0.73871871, 0.73490559, 0.73733662,\n",
       "          0.74692623, 0.74391321, 0.74362966, 0.74072887, 0.74514048]),\n",
       "   'train_roc_auc': array([0.99872323, 0.99851931, 0.99896056, 0.99857838, 0.99859336,\n",
       "          0.99856636, 0.99861391, 0.99875491, 0.99869569, 0.99872878]),\n",
       "   'test_accuracy': array([0.93536211, 0.93606983, 0.93818568, 0.93441076, 0.93417483,\n",
       "          0.93783178, 0.93770647, 0.93558282, 0.9362907 , 0.93640868]),\n",
       "   'train_accuracy': array([0.98864858, 0.98866169, 0.98919925, 0.98896331, 0.98883223,\n",
       "          0.98905507, 0.98919939, 0.98931736, 0.98874063, 0.98950087]),\n",
       "   'test_precision': array([0.51111111, 0.53773585, 0.64044944, 0.46956522, 0.46153846,\n",
       "          0.61458333, 0.6039604 , 0.51094891, 0.54368932, 0.54901961]),\n",
       "   'train_precision': array([0.99562257, 0.99466149, 0.99686369, 0.99636892, 0.99444042,\n",
       "          0.99733656, 0.9954294 , 0.99425287, 0.99587178, 0.9964046 ]),\n",
       "   'test_recall': array([0.08363636, 0.10363636, 0.10382514, 0.09836066, 0.09836066,\n",
       "          0.10746812, 0.11111111, 0.12750455, 0.10200364, 0.10200364]),\n",
       "   'train_recall': array([0.82840955, 0.82942129, 0.8359296 , 0.8326927 , 0.83228808,\n",
       "          0.83329962, 0.83714344, 0.83997572, 0.8296581 , 0.84098725])}],\n",
       " [10,\n",
       "  'log2',\n",
       "  {'fit_time': array([0.90757298, 0.85704613, 0.9222908 , 0.88488579, 0.87522197,\n",
       "          1.06933379, 0.90247726, 0.9066143 , 0.88392758, 0.94130564]),\n",
       "   'score_time': array([0.10874891, 0.116997  , 0.1196425 , 0.10671616, 0.10790133,\n",
       "          0.11851954, 0.11070323, 0.11269712, 0.11006951, 0.10870719]),\n",
       "   'test_roc_auc': array([0.73778128, 0.73646282, 0.74593093, 0.71938004, 0.74710877,\n",
       "          0.74822595, 0.74894489, 0.7411573 , 0.74898545, 0.74691165]),\n",
       "   'train_roc_auc': array([0.9986456 , 0.99862499, 0.99886161, 0.99884247, 0.99854091,\n",
       "          0.99865692, 0.99854145, 0.99873765, 0.99876115, 0.99863872]),\n",
       "   'test_accuracy': array([0.93430054, 0.93441849, 0.93594432, 0.93523652, 0.93618025,\n",
       "          0.93724195, 0.93676262, 0.93605474, 0.93499292, 0.93487494]),\n",
       "   'train_accuracy': array([0.98863547, 0.98849128, 0.98900263, 0.98923857, 0.98898953,\n",
       "          0.98867494, 0.98858334, 0.98866198, 0.98917318, 0.98898967]),\n",
       "   'test_precision': array([0.46236559, 0.46511628, 0.53488372, 0.5       , 0.54255319,\n",
       "          0.58762887, 0.56701031, 0.53398058, 0.48780488, 0.48351648]),\n",
       "   'train_precision': array([0.9953805 , 0.99488553, 0.99326923, 0.99662651, 0.99685154,\n",
       "          0.99659119, 0.99393498, 0.99634859, 0.99518884, 0.99541174]),\n",
       "   'test_recall': array([0.07818182, 0.07272727, 0.08378871, 0.09653916, 0.09289617,\n",
       "          0.10382514, 0.10018215, 0.10018215, 0.07285974, 0.08014572]),\n",
       "   'train_recall': array([0.82840955, 0.82658843, 0.8359296 , 0.83673882, 0.8326927 ,\n",
       "          0.82803965, 0.82884888, 0.82803965, 0.83694113, 0.83390653])}],\n",
       " [10,\n",
       "  None,\n",
       "  {'fit_time': array([5.96496153, 5.64823151, 6.16073823, 5.80211282, 5.57998848,\n",
       "          6.93855166, 5.81948066, 5.76433778, 5.65003753, 5.79686069]),\n",
       "   'score_time': array([0.13464236, 0.09773707, 0.0952127 , 0.0973084 , 0.09378171,\n",
       "          0.10172606, 0.1071763 , 0.1047492 , 0.09170508, 0.09810328]),\n",
       "   'test_roc_auc': array([0.734384  , 0.74895193, 0.72505016, 0.7242343 , 0.7513683 ,\n",
       "          0.73607768, 0.74744682, 0.74179288, 0.74565991, 0.7305274 ]),\n",
       "   'train_roc_auc': array([0.99820923, 0.99852058, 0.99867635, 0.99860525, 0.99832379,\n",
       "          0.99827368, 0.99839247, 0.99844462, 0.99855139, 0.99834315]),\n",
       "   'test_accuracy': array([0.9321774 , 0.93477235, 0.93370296, 0.93334906, 0.9325233 ,\n",
       "          0.93441076, 0.9357008 , 0.93522888, 0.93369514, 0.93369514]),\n",
       "   'train_accuracy': array([0.98963167, 0.9893564 , 0.98906817, 0.98934344, 0.98951384,\n",
       "          0.98925168, 0.989396  , 0.9888717 , 0.98952708, 0.98931736]),\n",
       "   'test_precision': array([0.42138365, 0.49056604, 0.46285714, 0.45348837, 0.43715847,\n",
       "          0.48066298, 0.51111111, 0.5       , 0.46242775, 0.46327684]),\n",
       "   'train_precision': array([0.99381394, 0.99378288, 0.99304056, 0.99425562, 0.99333175,\n",
       "          0.9923573 , 0.99378882, 0.99325301, 0.99380362, 0.9937799 ]),\n",
       "   'test_recall': array([0.12181818, 0.14181818, 0.14754098, 0.1420765 , 0.14571949,\n",
       "          0.15846995, 0.16757741, 0.15664845, 0.14571949, 0.14936248]),\n",
       "   'train_recall': array([0.84520437, 0.84095508, 0.83714344, 0.84038034, 0.84381954,\n",
       "          0.84058264, 0.84159417, 0.83390653, 0.84361724, 0.84038034])}],\n",
       " [55,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([5.58880997, 5.61631942, 5.22931695, 6.56211519, 5.38584924,\n",
       "          5.42772961, 5.71311617, 6.37488461, 6.05399036, 7.82995224]),\n",
       "   'score_time': array([0.48397756, 0.50357366, 0.46001434, 0.49524689, 0.49158096,\n",
       "          0.47246361, 0.50266981, 0.54462194, 0.50190663, 0.54414964]),\n",
       "   'test_roc_auc': array([0.79814123, 0.80335783, 0.79372883, 0.77876021, 0.80557072,\n",
       "          0.80982841, 0.80237093, 0.79381839, 0.80002312, 0.79852975]),\n",
       "   'train_roc_auc': array([0.99904276, 0.99907863, 0.99930868, 0.99918831, 0.99905661,\n",
       "          0.99915313, 0.99916255, 0.99919436, 0.99918422, 0.99916346]),\n",
       "   'test_accuracy': array([0.93583392, 0.93760321, 0.93960127, 0.93500059, 0.93794975,\n",
       "          0.940545  , 0.93935819, 0.93758849, 0.93959415, 0.93900425]),\n",
       "   'train_accuracy': array([0.99837462, 0.99809936, 0.99828289, 0.998296  , 0.998296  ,\n",
       "          0.99820424, 0.99824359, 0.99824359, 0.99832224, 0.99826981]),\n",
       "   'test_precision': array([0.53488372, 0.61052632, 0.69072165, 0.49038462, 0.60747664,\n",
       "          0.7027027 , 0.68041237, 0.59090909, 0.68686869, 0.65686275]),\n",
       "   'train_precision': array([0.99958523, 0.99833784, 0.99937733, 0.99854982, 0.9989633 ,\n",
       "          0.99916909, 0.99979214, 0.99834197, 0.9997924 , 0.99958463]),\n",
       "   'test_recall': array([0.08363636, 0.10545455, 0.12204007, 0.09289617, 0.11839709,\n",
       "          0.1420765 , 0.12021858, 0.11839709, 0.12386157, 0.12204007]),\n",
       "   'train_recall': array([0.97531364, 0.97227843, 0.97410479, 0.97511633, 0.97471171,\n",
       "          0.97309326, 0.97309326, 0.97450941, 0.9743071 , 0.97370018])}],\n",
       " [55,\n",
       "  'log2',\n",
       "  {'fit_time': array([10.38747644,  5.72592425,  5.76393652,  4.49206805,  6.02183962,\n",
       "           4.78929114,  4.53391314,  5.0318253 ,  4.720227  ,  4.79477906]),\n",
       "   'score_time': array([1.1588037 , 0.49036551, 0.52500844, 0.53655124, 0.51790595,\n",
       "          0.53539109, 0.66236353, 0.54265547, 0.5672102 , 0.60161209]),\n",
       "   'test_roc_auc': array([0.79986836, 0.80256616, 0.78834246, 0.77956297, 0.80157931,\n",
       "          0.81249334, 0.80135287, 0.79586863, 0.80408534, 0.79736556]),\n",
       "   'train_roc_auc': array([0.99908154, 0.99911396, 0.99938862, 0.99927719, 0.9991619 ,\n",
       "          0.99916091, 0.99919494, 0.9992124 , 0.99923748, 0.99921165]),\n",
       "   'test_accuracy': array([0.93618778, 0.93701345, 0.93877551, 0.93523652, 0.93806771,\n",
       "          0.93983721, 0.93912223, 0.93699858, 0.93912223, 0.93829637]),\n",
       "   'train_accuracy': array([0.9983353 , 0.99823044, 0.99837464, 0.99833532, 0.99811249,\n",
       "          0.99820424, 0.99809941, 0.99809941, 0.99813873, 0.99824359]),\n",
       "   'test_precision': array([0.55421687, 0.60810811, 0.66666667, 0.5       , 0.63953488,\n",
       "          0.72941176, 0.68965517, 0.57894737, 0.67368421, 0.65116279]),\n",
       "   'train_precision': array([0.99937772, 0.99916926, 0.99896459, 0.99958506, 0.99958359,\n",
       "          0.9995842 , 0.99916771, 0.9985453 , 0.99875338, 0.99937695]),\n",
       "   'test_recall': array([0.08363636, 0.08181818, 0.10928962, 0.07285974, 0.10018215,\n",
       "          0.1129326 , 0.10928962, 0.10018215, 0.11657559, 0.10200364]),\n",
       "   'train_recall': array([0.97490894, 0.97349251, 0.97592555, 0.97471171, 0.97127251,\n",
       "          0.97268865, 0.97147481, 0.97208173, 0.97248634, 0.97349788])}],\n",
       " [55,\n",
       "  None,\n",
       "  {'fit_time': array([34.34606791, 32.48618293, 33.64213729, 35.05411506, 31.97535419,\n",
       "          32.29156661, 32.81961179, 32.2347095 , 31.57030773, 32.74931192]),\n",
       "   'score_time': array([0.65365219, 0.41665792, 0.51905084, 0.4456389 , 0.42793798,\n",
       "          0.41386914, 0.39295101, 0.40920806, 0.49616575, 0.52854729]),\n",
       "   'test_roc_auc': array([0.77470794, 0.79530318, 0.77837054, 0.76604916, 0.78601344,\n",
       "          0.78963001, 0.78391219, 0.77581589, 0.79342454, 0.78470805]),\n",
       "   'train_roc_auc': array([0.99892047, 0.99893817, 0.99914833, 0.99909854, 0.99893954,\n",
       "          0.99898385, 0.99894873, 0.99898886, 0.99912151, 0.99895001]),\n",
       "   'test_accuracy': array([0.93430054, 0.93701345, 0.93618025, 0.93429279, 0.93629822,\n",
       "          0.93877551, 0.93676262, 0.93593676, 0.93581878, 0.93711656]),\n",
       "   'train_accuracy': array([0.99836152, 0.99811247, 0.99832221, 0.99824357, 0.99830911,\n",
       "          0.99806006, 0.99816495, 0.99812562, 0.99812562, 0.99826981]),\n",
       "   'test_precision': array([0.47741935, 0.55405405, 0.52631579, 0.47260274, 0.52830189,\n",
       "          0.60273973, 0.54304636, 0.51724138, 0.51592357, 0.54878049]),\n",
       "   'train_precision': array([0.99917098, 0.99937552, 0.99855042, 0.99875544, 0.99896352,\n",
       "          0.99958325, 0.99958394, 0.99875312, 0.998132  , 0.99896287]),\n",
       "   'test_recall': array([0.13454545, 0.14909091, 0.14571949, 0.12568306, 0.15300546,\n",
       "          0.16029144, 0.14936248, 0.16393443, 0.14754098, 0.16393443]),\n",
       "   'train_recall': array([0.97551599, 0.97146904, 0.97552094, 0.97410479, 0.97491402,\n",
       "          0.97046328, 0.97208173, 0.97228404, 0.97289096, 0.9743071 ])}],\n",
       " [100,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([10.65185285,  9.95076036, 11.06154895, 10.2982614 ,  9.64708829,\n",
       "          10.99517393,  9.97855353, 10.29028678, 10.81175041,  9.61429024]),\n",
       "   'score_time': array([0.85719156, 0.99040318, 0.87871385, 1.02098179, 0.91173601,\n",
       "          0.97119689, 0.88486814, 0.83806133, 1.10915136, 0.84092975]),\n",
       "   'test_roc_auc': array([0.80109485, 0.81018186, 0.7943703 , 0.78135356, 0.81152917,\n",
       "          0.81498502, 0.81062544, 0.80029104, 0.80779003, 0.8066032 ]),\n",
       "   'train_roc_auc': array([0.99916537, 0.99917618, 0.99936612, 0.99927348, 0.99922177,\n",
       "          0.99919413, 0.99917992, 0.99923211, 0.99930101, 0.99920063]),\n",
       "   'test_accuracy': array([0.93689549, 0.9371314 , 0.93948331, 0.93688805, 0.93712398,\n",
       "          0.94019111, 0.93865031, 0.93782445, 0.93935819, 0.93829637]),\n",
       "   'train_accuracy': array([0.99854503, 0.99840084, 0.99857126, 0.99850572, 0.99847951,\n",
       "          0.99845329, 0.9984271 , 0.99851885, 0.99846642, 0.99845331]),\n",
       "   'test_precision': array([0.59493671, 0.60759494, 0.7       , 0.57608696, 0.58      ,\n",
       "          0.71875   , 0.65934066, 0.61956522, 0.68041237, 0.63265306]),\n",
       "   'train_precision': array([0.99937978, 0.99958541, 0.99958661, 0.99958618, 0.99958601,\n",
       "          0.99917236, 0.99937875, 1.        , 1.        , 0.99979283]),\n",
       "   'test_recall': array([0.08545455, 0.08727273, 0.1147541 , 0.09653916, 0.10564663,\n",
       "          0.12568306, 0.10928962, 0.10382514, 0.12021858, 0.1129326 ]),\n",
       "   'train_recall': array([0.9781465 , 0.97571833, 0.97835323, 0.9773417 , 0.97693708,\n",
       "          0.97693708, 0.97633016, 0.97713939, 0.97633016, 0.97633016])}],\n",
       " [100,\n",
       "  'log2',\n",
       "  {'fit_time': array([8.86474085, 8.96817493, 9.59471726, 8.65713906, 9.23419642,\n",
       "          8.89925098, 8.20222878, 8.16009736, 7.98608661, 8.25445676]),\n",
       "   'score_time': array([0.98570538, 1.02272868, 0.87876081, 0.86278558, 0.95401621,\n",
       "          0.9793725 , 0.85667539, 0.8780725 , 0.85678434, 1.30807161]),\n",
       "   'test_roc_auc': array([0.7980261 , 0.80491159, 0.80130923, 0.78420194, 0.81058178,\n",
       "          0.81253021, 0.80818112, 0.79850149, 0.81973992, 0.80562374]),\n",
       "   'train_roc_auc': array([0.99914101, 0.99918538, 0.99937737, 0.99929198, 0.99914954,\n",
       "          0.99922442, 0.99921145, 0.99925447, 0.99930625, 0.9991851 ]),\n",
       "   'test_accuracy': array([0.93654164, 0.93677754, 0.93842161, 0.93700602, 0.93877551,\n",
       "          0.94007314, 0.93888627, 0.93782445, 0.93782445, 0.93841435]),\n",
       "   'train_accuracy': array([0.99846638, 0.99838773, 0.99861058, 0.99849261, 0.99845329,\n",
       "          0.99844018, 0.99834845, 0.99849263, 0.99850574, 0.99849263]),\n",
       "   'test_precision': array([0.58108108, 0.59722222, 0.68      , 0.5974026 , 0.67045455,\n",
       "          0.74117647, 0.68674699, 0.63414634, 0.64473684, 0.65517241]),\n",
       "   'train_precision': array([1.        , 1.        , 0.99958686, 0.99958609, 0.99979283,\n",
       "          0.99979279, 0.99979249, 0.99958609, 0.99958618, 0.99958609]),\n",
       "   'test_recall': array([0.07818182, 0.07818182, 0.09289617, 0.08378871, 0.10746812,\n",
       "          0.1147541 , 0.10382514, 0.09471767, 0.08925319, 0.10382514]),\n",
       "   'train_recall': array([0.97632537, 0.97511129, 0.97896015, 0.97713939, 0.97633016,\n",
       "          0.97612786, 0.97471171, 0.97713939, 0.9773417 , 0.97713939])}],\n",
       " [100,\n",
       "  None,\n",
       "  {'fit_time': array([52.47359467, 51.98531437, 52.57543206, 48.95297289, 48.20046115,\n",
       "          48.0131495 , 48.16723347, 49.04265547, 48.03725958, 48.43607783]),\n",
       "   'score_time': array([0.94449019, 0.72712374, 0.61262631, 0.69377398, 0.60166931,\n",
       "          0.60159588, 0.59960842, 0.60242748, 0.59833455, 0.62198925]),\n",
       "   'test_roc_auc': array([0.78128211, 0.7913602 , 0.78477082, 0.77080542, 0.79784844,\n",
       "          0.79627428, 0.78846099, 0.77854181, 0.78839113, 0.78987909]),\n",
       "   'train_roc_auc': array([0.99896406, 0.99896665, 0.99917744, 0.99907399, 0.99895585,\n",
       "          0.9990305 , 0.99897816, 0.99907529, 0.99907583, 0.99896896]),\n",
       "   'test_accuracy': array([0.93536211, 0.93854683, 0.93735992, 0.93476466, 0.93665212,\n",
       "          0.93901144, 0.93865031, 0.93735252, 0.93711656, 0.93605474]),\n",
       "   'train_accuracy': array([0.99847949, 0.99837462, 0.99861058, 0.99849261, 0.99845329,\n",
       "          0.99844018, 0.9984402 , 0.99850574, 0.99849263, 0.9984402 ]),\n",
       "   'test_precision': array([0.50714286, 0.60740741, 0.56923077, 0.48684211, 0.54166667,\n",
       "          0.61594203, 0.60902256, 0.55487805, 0.55633803, 0.52095808]),\n",
       "   'train_precision': array([0.99958592, 0.99958523, 0.99958686, 0.99979296, 0.99979283,\n",
       "          0.99958575, 0.99937888, 0.99958618, 0.99979296, 0.99958575]),\n",
       "   'test_recall': array([0.12909091, 0.14909091, 0.13479053, 0.13479053, 0.1420765 ,\n",
       "          0.15482696, 0.14754098, 0.16575592, 0.143898  , 0.15846995]),\n",
       "   'train_recall': array([0.97693242, 0.97531364, 0.97896015, 0.97693708, 0.97633016,\n",
       "          0.97633016, 0.97653247, 0.9773417 , 0.97693708, 0.97633016])}],\n",
       " [200,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([16.88991714, 16.15531349, 17.25767183, 16.0572176 , 16.14607453,\n",
       "          16.09076548, 16.07183242, 16.75425291, 16.23703265, 17.35864019]),\n",
       "   'score_time': array([1.43190479, 1.42781472, 1.38274431, 2.50950527, 1.38953257,\n",
       "          1.38251352, 1.49155688, 1.53517556, 1.38802195, 1.3891499 ]),\n",
       "   'test_roc_auc': array([0.80305442, 0.81290512, 0.7986056 , 0.7880478 , 0.81226197,\n",
       "          0.81509404, 0.81455543, 0.79763383, 0.81337664, 0.81552075]),\n",
       "   'train_roc_auc': array([0.99916356, 0.99926875, 0.99937127, 0.99930321, 0.99920829,\n",
       "          0.9992301 , 0.99922091, 0.99924164, 0.99931102, 0.9992154 ]),\n",
       "   'test_accuracy': array([0.93724935, 0.93748526, 0.93889348, 0.93665212, 0.93759585,\n",
       "          0.94113484, 0.93900425, 0.93888627, 0.93876829, 0.93924021]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99847951,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.61538462, 0.62820513, 0.67816092, 0.56521739, 0.59615385,\n",
       "          0.76041667, 0.67021277, 0.67032967, 0.65306122, 0.67346939]),\n",
       "   'train_precision': array([0.99979317, 1.        , 0.99979343, 1.        , 1.        ,\n",
       "          1.        , 0.99958584, 0.99958635, 1.        , 1.        ]),\n",
       "   'test_recall': array([0.08727273, 0.08909091, 0.10746812, 0.09471767, 0.1129326 ,\n",
       "          0.13296903, 0.1147541 , 0.11111111, 0.11657559, 0.12021858]),\n",
       "   'train_recall': array([0.9781465 , 0.97571833, 0.97916245, 0.9773417 , 0.97653247,\n",
       "          0.97633016, 0.97653247, 0.97774631, 0.9773417 , 0.97693708])}],\n",
       " [200,\n",
       "  'log2',\n",
       "  {'fit_time': array([14.03870583, 15.08806562, 14.18759036, 14.15712786, 13.82458019,\n",
       "          13.87329221, 13.72226429, 13.86636066, 15.14586878, 14.08965206]),\n",
       "   'score_time': array([1.40442753, 1.42876172, 1.42513394, 1.48924518, 1.78036761,\n",
       "          1.42195463, 1.44271898, 1.42397594, 1.4199245 , 1.55064058]),\n",
       "   'test_roc_auc': array([0.80458559, 0.81508417, 0.80137035, 0.78389005, 0.81671691,\n",
       "          0.81959781, 0.81201517, 0.7979723 , 0.81626731, 0.81111316]),\n",
       "   'train_roc_auc': array([0.99921335, 0.99924824, 0.9993766 , 0.99931264, 0.9992395 ,\n",
       "          0.99924478, 0.99921069, 0.9992667 , 0.99933583, 0.99923174]),\n",
       "   'test_accuracy': array([0.9371314 , 0.93748526, 0.93818568, 0.93665212, 0.93735992,\n",
       "          0.94101687, 0.93947617, 0.93711656, 0.93924021, 0.93829637]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.62318841, 0.63888889, 0.66233766, 0.57692308, 0.60714286,\n",
       "          0.78823529, 0.73076923, 0.58510638, 0.70238095, 0.63829787]),\n",
       "   'train_precision': array([1.        , 1.        , 1.        , 1.        , 0.99979296,\n",
       "          0.99979287, 0.99958584, 0.99979309, 1.        , 1.        ]),\n",
       "   'test_recall': array([0.07818182, 0.08363636, 0.09289617, 0.08196721, 0.09289617,\n",
       "          0.12204007, 0.10382514, 0.10018215, 0.10746812, 0.10928962]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97693708,\n",
       "          0.97653247, 0.97653247, 0.977544  , 0.9773417 , 0.97693708])}],\n",
       " [200,\n",
       "  None,\n",
       "  {'fit_time': array([96.32272148, 94.07389879, 94.91486216, 96.18113112, 94.08571148,\n",
       "          97.63220501, 94.53732419, 94.5298202 , 96.68483829, 94.14158559]),\n",
       "   'score_time': array([1.1947639 , 1.18007374, 1.18248153, 1.20731378, 1.19408751,\n",
       "          1.26380301, 1.33187556, 1.21061707, 1.17630768, 1.20890903]),\n",
       "   'test_roc_auc': array([0.78433733, 0.80190372, 0.78357483, 0.7727496 , 0.7999986 ,\n",
       "          0.79909796, 0.79466273, 0.78217744, 0.79364306, 0.79250023]),\n",
       "   'train_roc_auc': array([0.99897441, 0.99902731, 0.99923748, 0.99910883, 0.99899308,\n",
       "          0.99906794, 0.99903464, 0.99908265, 0.99916046, 0.99902391]),\n",
       "   'test_accuracy': array([0.93571597, 0.93842887, 0.93735992, 0.93464669, 0.93629822,\n",
       "          0.93995517, 0.93817839, 0.93735252, 0.93770647, 0.93758849]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99849263]),\n",
       "   'test_precision': array([0.51798561, 0.60606061, 0.56923077, 0.48148148, 0.52980132,\n",
       "          0.64925373, 0.59398496, 0.55487805, 0.57664234, 0.5625    ]),\n",
       "   'train_precision': array([1.        , 1.        , 0.99979343, 1.        , 0.99958609,\n",
       "          1.        , 1.        , 0.99979309, 0.99979309, 1.        ]),\n",
       "   'test_recall': array([0.13090909, 0.14545455, 0.13479053, 0.11839709, 0.14571949,\n",
       "          0.15846995, 0.143898  , 0.16575592, 0.143898  , 0.16393443]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97916245, 0.9773417 , 0.97713939,\n",
       "          0.97633016, 0.97612786, 0.977544  , 0.977544  , 0.97673478])}],\n",
       " [1000,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([83.35066772, 82.1224792 , 83.83868337, 81.77533221, 82.02014112,\n",
       "          83.79094911, 85.14308834, 92.43937278, 83.16639614, 86.43093657]),\n",
       "   'score_time': array([7.21336317, 7.12609363, 7.46482182, 7.09864497, 7.61605334,\n",
       "          7.15576816, 7.12252116, 7.38745117, 7.01713896, 9.39694786]),\n",
       "   'test_roc_auc': array([0.80750206, 0.81577206, 0.80336117, 0.78974328, 0.81763766,\n",
       "          0.82083745, 0.81427394, 0.80104071, 0.8162209 , 0.81395271]),\n",
       "   'train_roc_auc': array([0.99922036, 0.99926115, 0.99939184, 0.99931951, 0.99922704,\n",
       "          0.99926032, 0.999247  , 0.99926643, 0.9993434 , 0.99923703]),\n",
       "   'test_accuracy': array([0.93701345, 0.93748526, 0.93853958, 0.93665212, 0.93830365,\n",
       "          0.9408989 , 0.93959415, 0.93770647, 0.93959415, 0.93900425]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.59756098, 0.62820513, 0.6627907 , 0.56666667, 0.62745098,\n",
       "          0.75531915, 0.69473684, 0.60824742, 0.69473684, 0.67021277]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.08909091, 0.08909091, 0.10382514, 0.09289617, 0.11657559,\n",
       "          0.12932605, 0.12021858, 0.10746812, 0.12021858, 0.1147541 ]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}],\n",
       " [1000,\n",
       "  'log2',\n",
       "  {'fit_time': array([ 91.30245781, 100.66317987,  88.68085146,  74.25791669,\n",
       "           78.75498533,  75.61559653,  76.74828649,  72.60451078,\n",
       "           81.01999259,  73.73780131]),\n",
       "   'score_time': array([9.66082907, 8.14773297, 7.39311647, 7.43675637, 8.21505666,\n",
       "          8.47682953, 8.75386524, 7.53796721, 8.06954622, 7.58465791]),\n",
       "   'test_roc_auc': array([0.80724349, 0.81805603, 0.80368685, 0.79122094, 0.81902434,\n",
       "          0.82027191, 0.81571848, 0.80229809, 0.81745426, 0.8159794 ]),\n",
       "   'train_roc_auc': array([0.99925039, 0.99928378, 0.99941296, 0.99934645, 0.99925328,\n",
       "          0.99929125, 0.99927709, 0.99928105, 0.99936303, 0.99926005]),\n",
       "   'test_accuracy': array([0.93701345, 0.93701345, 0.93842161, 0.93665212, 0.93783178,\n",
       "          0.94019111, 0.93912223, 0.93735252, 0.93888627, 0.93876829]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.61428571, 0.60810811, 0.68      , 0.57894737, 0.62222222,\n",
       "          0.74418605, 0.71428571, 0.6       , 0.68674699, 0.6744186 ]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.07818182, 0.08181818, 0.09289617, 0.08014572, 0.10200364,\n",
       "          0.11657559, 0.10018215, 0.09836066, 0.10382514, 0.10564663]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}],\n",
       " [1000,\n",
       "  None,\n",
       "  {'fit_time': array([ 533.1738143 ,  506.2536633 ,  492.91550231,  486.5309217 ,\n",
       "           957.53897643,  522.35984731,  492.65388012,  982.35089016,\n",
       "          2168.53665113,  983.43033648]),\n",
       "   'score_time': array([ 6.77443004,  6.17230916,  6.97112751,  6.11215091, 14.2206285 ,\n",
       "           6.12467408,  6.5910511 , 13.9248755 , 13.70360565, 10.68248868]),\n",
       "   'test_roc_auc': array([0.78780616, 0.80351355, 0.78592131, 0.7727527 , 0.80067718,\n",
       "          0.79856344, 0.7975711 , 0.78683791, 0.79502268, 0.79568687]),\n",
       "   'train_roc_auc': array([0.99900407, 0.99904032, 0.99924474, 0.99911954, 0.99901425,\n",
       "          0.9990636 , 0.99903427, 0.99909323, 0.99916122, 0.99902446]),\n",
       "   'test_accuracy': array([0.93642368, 0.93795707, 0.93759585, 0.93511856, 0.93747788,\n",
       "          0.93983721, 0.93817839, 0.93876829, 0.93782445, 0.93723454]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.54198473, 0.5952381 , 0.58064516, 0.49640288, 0.56551724,\n",
       "          0.64885496, 0.59689922, 0.59146341, 0.58088235, 0.55414013]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.12909091, 0.13636364, 0.13114754, 0.12568306, 0.14936248,\n",
       "          0.15482696, 0.14025501, 0.17668488, 0.143898  , 0.15846995]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_rf1.pkl', 'wb') as f:\n",
    "    pickle.dump(res_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_rf1.pkl', 'rb') as f:\n",
    "    res_rf2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_roc_auc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\akhil\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([1.08280468, 0.98315859, 1.05116796, 0.96878433, 1.07296205,\n",
       "          1.25250459, 1.0642283 , 1.0701232 , 1.02904677, 1.02408957]),\n",
       "   'score_time': array([0.11467409, 0.09915996, 0.10468006, 0.10599256, 0.10172772,\n",
       "          0.10073447, 0.09719014, 0.10925341, 0.11868382, 0.11089134]),\n",
       "   'test_roc_auc': array([0.7291901 , 0.7518441 , 0.73871871, 0.73490559, 0.73733662,\n",
       "          0.74692623, 0.74391321, 0.74362966, 0.74072887, 0.74514048]),\n",
       "   'train_roc_auc': array([0.99872323, 0.99851931, 0.99896056, 0.99857838, 0.99859336,\n",
       "          0.99856636, 0.99861391, 0.99875491, 0.99869569, 0.99872878]),\n",
       "   'test_accuracy': array([0.93536211, 0.93606983, 0.93818568, 0.93441076, 0.93417483,\n",
       "          0.93783178, 0.93770647, 0.93558282, 0.9362907 , 0.93640868]),\n",
       "   'train_accuracy': array([0.98864858, 0.98866169, 0.98919925, 0.98896331, 0.98883223,\n",
       "          0.98905507, 0.98919939, 0.98931736, 0.98874063, 0.98950087]),\n",
       "   'test_precision': array([0.51111111, 0.53773585, 0.64044944, 0.46956522, 0.46153846,\n",
       "          0.61458333, 0.6039604 , 0.51094891, 0.54368932, 0.54901961]),\n",
       "   'train_precision': array([0.99562257, 0.99466149, 0.99686369, 0.99636892, 0.99444042,\n",
       "          0.99733656, 0.9954294 , 0.99425287, 0.99587178, 0.9964046 ]),\n",
       "   'test_recall': array([0.08363636, 0.10363636, 0.10382514, 0.09836066, 0.09836066,\n",
       "          0.10746812, 0.11111111, 0.12750455, 0.10200364, 0.10200364]),\n",
       "   'train_recall': array([0.82840955, 0.82942129, 0.8359296 , 0.8326927 , 0.83228808,\n",
       "          0.83329962, 0.83714344, 0.83997572, 0.8296581 , 0.84098725])}],\n",
       " [10,\n",
       "  'log2',\n",
       "  {'fit_time': array([0.90757298, 0.85704613, 0.9222908 , 0.88488579, 0.87522197,\n",
       "          1.06933379, 0.90247726, 0.9066143 , 0.88392758, 0.94130564]),\n",
       "   'score_time': array([0.10874891, 0.116997  , 0.1196425 , 0.10671616, 0.10790133,\n",
       "          0.11851954, 0.11070323, 0.11269712, 0.11006951, 0.10870719]),\n",
       "   'test_roc_auc': array([0.73778128, 0.73646282, 0.74593093, 0.71938004, 0.74710877,\n",
       "          0.74822595, 0.74894489, 0.7411573 , 0.74898545, 0.74691165]),\n",
       "   'train_roc_auc': array([0.9986456 , 0.99862499, 0.99886161, 0.99884247, 0.99854091,\n",
       "          0.99865692, 0.99854145, 0.99873765, 0.99876115, 0.99863872]),\n",
       "   'test_accuracy': array([0.93430054, 0.93441849, 0.93594432, 0.93523652, 0.93618025,\n",
       "          0.93724195, 0.93676262, 0.93605474, 0.93499292, 0.93487494]),\n",
       "   'train_accuracy': array([0.98863547, 0.98849128, 0.98900263, 0.98923857, 0.98898953,\n",
       "          0.98867494, 0.98858334, 0.98866198, 0.98917318, 0.98898967]),\n",
       "   'test_precision': array([0.46236559, 0.46511628, 0.53488372, 0.5       , 0.54255319,\n",
       "          0.58762887, 0.56701031, 0.53398058, 0.48780488, 0.48351648]),\n",
       "   'train_precision': array([0.9953805 , 0.99488553, 0.99326923, 0.99662651, 0.99685154,\n",
       "          0.99659119, 0.99393498, 0.99634859, 0.99518884, 0.99541174]),\n",
       "   'test_recall': array([0.07818182, 0.07272727, 0.08378871, 0.09653916, 0.09289617,\n",
       "          0.10382514, 0.10018215, 0.10018215, 0.07285974, 0.08014572]),\n",
       "   'train_recall': array([0.82840955, 0.82658843, 0.8359296 , 0.83673882, 0.8326927 ,\n",
       "          0.82803965, 0.82884888, 0.82803965, 0.83694113, 0.83390653])}],\n",
       " [10,\n",
       "  None,\n",
       "  {'fit_time': array([5.96496153, 5.64823151, 6.16073823, 5.80211282, 5.57998848,\n",
       "          6.93855166, 5.81948066, 5.76433778, 5.65003753, 5.79686069]),\n",
       "   'score_time': array([0.13464236, 0.09773707, 0.0952127 , 0.0973084 , 0.09378171,\n",
       "          0.10172606, 0.1071763 , 0.1047492 , 0.09170508, 0.09810328]),\n",
       "   'test_roc_auc': array([0.734384  , 0.74895193, 0.72505016, 0.7242343 , 0.7513683 ,\n",
       "          0.73607768, 0.74744682, 0.74179288, 0.74565991, 0.7305274 ]),\n",
       "   'train_roc_auc': array([0.99820923, 0.99852058, 0.99867635, 0.99860525, 0.99832379,\n",
       "          0.99827368, 0.99839247, 0.99844462, 0.99855139, 0.99834315]),\n",
       "   'test_accuracy': array([0.9321774 , 0.93477235, 0.93370296, 0.93334906, 0.9325233 ,\n",
       "          0.93441076, 0.9357008 , 0.93522888, 0.93369514, 0.93369514]),\n",
       "   'train_accuracy': array([0.98963167, 0.9893564 , 0.98906817, 0.98934344, 0.98951384,\n",
       "          0.98925168, 0.989396  , 0.9888717 , 0.98952708, 0.98931736]),\n",
       "   'test_precision': array([0.42138365, 0.49056604, 0.46285714, 0.45348837, 0.43715847,\n",
       "          0.48066298, 0.51111111, 0.5       , 0.46242775, 0.46327684]),\n",
       "   'train_precision': array([0.99381394, 0.99378288, 0.99304056, 0.99425562, 0.99333175,\n",
       "          0.9923573 , 0.99378882, 0.99325301, 0.99380362, 0.9937799 ]),\n",
       "   'test_recall': array([0.12181818, 0.14181818, 0.14754098, 0.1420765 , 0.14571949,\n",
       "          0.15846995, 0.16757741, 0.15664845, 0.14571949, 0.14936248]),\n",
       "   'train_recall': array([0.84520437, 0.84095508, 0.83714344, 0.84038034, 0.84381954,\n",
       "          0.84058264, 0.84159417, 0.83390653, 0.84361724, 0.84038034])}],\n",
       " [55,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([5.58880997, 5.61631942, 5.22931695, 6.56211519, 5.38584924,\n",
       "          5.42772961, 5.71311617, 6.37488461, 6.05399036, 7.82995224]),\n",
       "   'score_time': array([0.48397756, 0.50357366, 0.46001434, 0.49524689, 0.49158096,\n",
       "          0.47246361, 0.50266981, 0.54462194, 0.50190663, 0.54414964]),\n",
       "   'test_roc_auc': array([0.79814123, 0.80335783, 0.79372883, 0.77876021, 0.80557072,\n",
       "          0.80982841, 0.80237093, 0.79381839, 0.80002312, 0.79852975]),\n",
       "   'train_roc_auc': array([0.99904276, 0.99907863, 0.99930868, 0.99918831, 0.99905661,\n",
       "          0.99915313, 0.99916255, 0.99919436, 0.99918422, 0.99916346]),\n",
       "   'test_accuracy': array([0.93583392, 0.93760321, 0.93960127, 0.93500059, 0.93794975,\n",
       "          0.940545  , 0.93935819, 0.93758849, 0.93959415, 0.93900425]),\n",
       "   'train_accuracy': array([0.99837462, 0.99809936, 0.99828289, 0.998296  , 0.998296  ,\n",
       "          0.99820424, 0.99824359, 0.99824359, 0.99832224, 0.99826981]),\n",
       "   'test_precision': array([0.53488372, 0.61052632, 0.69072165, 0.49038462, 0.60747664,\n",
       "          0.7027027 , 0.68041237, 0.59090909, 0.68686869, 0.65686275]),\n",
       "   'train_precision': array([0.99958523, 0.99833784, 0.99937733, 0.99854982, 0.9989633 ,\n",
       "          0.99916909, 0.99979214, 0.99834197, 0.9997924 , 0.99958463]),\n",
       "   'test_recall': array([0.08363636, 0.10545455, 0.12204007, 0.09289617, 0.11839709,\n",
       "          0.1420765 , 0.12021858, 0.11839709, 0.12386157, 0.12204007]),\n",
       "   'train_recall': array([0.97531364, 0.97227843, 0.97410479, 0.97511633, 0.97471171,\n",
       "          0.97309326, 0.97309326, 0.97450941, 0.9743071 , 0.97370018])}],\n",
       " [55,\n",
       "  'log2',\n",
       "  {'fit_time': array([10.38747644,  5.72592425,  5.76393652,  4.49206805,  6.02183962,\n",
       "           4.78929114,  4.53391314,  5.0318253 ,  4.720227  ,  4.79477906]),\n",
       "   'score_time': array([1.1588037 , 0.49036551, 0.52500844, 0.53655124, 0.51790595,\n",
       "          0.53539109, 0.66236353, 0.54265547, 0.5672102 , 0.60161209]),\n",
       "   'test_roc_auc': array([0.79986836, 0.80256616, 0.78834246, 0.77956297, 0.80157931,\n",
       "          0.81249334, 0.80135287, 0.79586863, 0.80408534, 0.79736556]),\n",
       "   'train_roc_auc': array([0.99908154, 0.99911396, 0.99938862, 0.99927719, 0.9991619 ,\n",
       "          0.99916091, 0.99919494, 0.9992124 , 0.99923748, 0.99921165]),\n",
       "   'test_accuracy': array([0.93618778, 0.93701345, 0.93877551, 0.93523652, 0.93806771,\n",
       "          0.93983721, 0.93912223, 0.93699858, 0.93912223, 0.93829637]),\n",
       "   'train_accuracy': array([0.9983353 , 0.99823044, 0.99837464, 0.99833532, 0.99811249,\n",
       "          0.99820424, 0.99809941, 0.99809941, 0.99813873, 0.99824359]),\n",
       "   'test_precision': array([0.55421687, 0.60810811, 0.66666667, 0.5       , 0.63953488,\n",
       "          0.72941176, 0.68965517, 0.57894737, 0.67368421, 0.65116279]),\n",
       "   'train_precision': array([0.99937772, 0.99916926, 0.99896459, 0.99958506, 0.99958359,\n",
       "          0.9995842 , 0.99916771, 0.9985453 , 0.99875338, 0.99937695]),\n",
       "   'test_recall': array([0.08363636, 0.08181818, 0.10928962, 0.07285974, 0.10018215,\n",
       "          0.1129326 , 0.10928962, 0.10018215, 0.11657559, 0.10200364]),\n",
       "   'train_recall': array([0.97490894, 0.97349251, 0.97592555, 0.97471171, 0.97127251,\n",
       "          0.97268865, 0.97147481, 0.97208173, 0.97248634, 0.97349788])}],\n",
       " [55,\n",
       "  None,\n",
       "  {'fit_time': array([34.34606791, 32.48618293, 33.64213729, 35.05411506, 31.97535419,\n",
       "          32.29156661, 32.81961179, 32.2347095 , 31.57030773, 32.74931192]),\n",
       "   'score_time': array([0.65365219, 0.41665792, 0.51905084, 0.4456389 , 0.42793798,\n",
       "          0.41386914, 0.39295101, 0.40920806, 0.49616575, 0.52854729]),\n",
       "   'test_roc_auc': array([0.77470794, 0.79530318, 0.77837054, 0.76604916, 0.78601344,\n",
       "          0.78963001, 0.78391219, 0.77581589, 0.79342454, 0.78470805]),\n",
       "   'train_roc_auc': array([0.99892047, 0.99893817, 0.99914833, 0.99909854, 0.99893954,\n",
       "          0.99898385, 0.99894873, 0.99898886, 0.99912151, 0.99895001]),\n",
       "   'test_accuracy': array([0.93430054, 0.93701345, 0.93618025, 0.93429279, 0.93629822,\n",
       "          0.93877551, 0.93676262, 0.93593676, 0.93581878, 0.93711656]),\n",
       "   'train_accuracy': array([0.99836152, 0.99811247, 0.99832221, 0.99824357, 0.99830911,\n",
       "          0.99806006, 0.99816495, 0.99812562, 0.99812562, 0.99826981]),\n",
       "   'test_precision': array([0.47741935, 0.55405405, 0.52631579, 0.47260274, 0.52830189,\n",
       "          0.60273973, 0.54304636, 0.51724138, 0.51592357, 0.54878049]),\n",
       "   'train_precision': array([0.99917098, 0.99937552, 0.99855042, 0.99875544, 0.99896352,\n",
       "          0.99958325, 0.99958394, 0.99875312, 0.998132  , 0.99896287]),\n",
       "   'test_recall': array([0.13454545, 0.14909091, 0.14571949, 0.12568306, 0.15300546,\n",
       "          0.16029144, 0.14936248, 0.16393443, 0.14754098, 0.16393443]),\n",
       "   'train_recall': array([0.97551599, 0.97146904, 0.97552094, 0.97410479, 0.97491402,\n",
       "          0.97046328, 0.97208173, 0.97228404, 0.97289096, 0.9743071 ])}],\n",
       " [100,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([10.65185285,  9.95076036, 11.06154895, 10.2982614 ,  9.64708829,\n",
       "          10.99517393,  9.97855353, 10.29028678, 10.81175041,  9.61429024]),\n",
       "   'score_time': array([0.85719156, 0.99040318, 0.87871385, 1.02098179, 0.91173601,\n",
       "          0.97119689, 0.88486814, 0.83806133, 1.10915136, 0.84092975]),\n",
       "   'test_roc_auc': array([0.80109485, 0.81018186, 0.7943703 , 0.78135356, 0.81152917,\n",
       "          0.81498502, 0.81062544, 0.80029104, 0.80779003, 0.8066032 ]),\n",
       "   'train_roc_auc': array([0.99916537, 0.99917618, 0.99936612, 0.99927348, 0.99922177,\n",
       "          0.99919413, 0.99917992, 0.99923211, 0.99930101, 0.99920063]),\n",
       "   'test_accuracy': array([0.93689549, 0.9371314 , 0.93948331, 0.93688805, 0.93712398,\n",
       "          0.94019111, 0.93865031, 0.93782445, 0.93935819, 0.93829637]),\n",
       "   'train_accuracy': array([0.99854503, 0.99840084, 0.99857126, 0.99850572, 0.99847951,\n",
       "          0.99845329, 0.9984271 , 0.99851885, 0.99846642, 0.99845331]),\n",
       "   'test_precision': array([0.59493671, 0.60759494, 0.7       , 0.57608696, 0.58      ,\n",
       "          0.71875   , 0.65934066, 0.61956522, 0.68041237, 0.63265306]),\n",
       "   'train_precision': array([0.99937978, 0.99958541, 0.99958661, 0.99958618, 0.99958601,\n",
       "          0.99917236, 0.99937875, 1.        , 1.        , 0.99979283]),\n",
       "   'test_recall': array([0.08545455, 0.08727273, 0.1147541 , 0.09653916, 0.10564663,\n",
       "          0.12568306, 0.10928962, 0.10382514, 0.12021858, 0.1129326 ]),\n",
       "   'train_recall': array([0.9781465 , 0.97571833, 0.97835323, 0.9773417 , 0.97693708,\n",
       "          0.97693708, 0.97633016, 0.97713939, 0.97633016, 0.97633016])}],\n",
       " [100,\n",
       "  'log2',\n",
       "  {'fit_time': array([8.86474085, 8.96817493, 9.59471726, 8.65713906, 9.23419642,\n",
       "          8.89925098, 8.20222878, 8.16009736, 7.98608661, 8.25445676]),\n",
       "   'score_time': array([0.98570538, 1.02272868, 0.87876081, 0.86278558, 0.95401621,\n",
       "          0.9793725 , 0.85667539, 0.8780725 , 0.85678434, 1.30807161]),\n",
       "   'test_roc_auc': array([0.7980261 , 0.80491159, 0.80130923, 0.78420194, 0.81058178,\n",
       "          0.81253021, 0.80818112, 0.79850149, 0.81973992, 0.80562374]),\n",
       "   'train_roc_auc': array([0.99914101, 0.99918538, 0.99937737, 0.99929198, 0.99914954,\n",
       "          0.99922442, 0.99921145, 0.99925447, 0.99930625, 0.9991851 ]),\n",
       "   'test_accuracy': array([0.93654164, 0.93677754, 0.93842161, 0.93700602, 0.93877551,\n",
       "          0.94007314, 0.93888627, 0.93782445, 0.93782445, 0.93841435]),\n",
       "   'train_accuracy': array([0.99846638, 0.99838773, 0.99861058, 0.99849261, 0.99845329,\n",
       "          0.99844018, 0.99834845, 0.99849263, 0.99850574, 0.99849263]),\n",
       "   'test_precision': array([0.58108108, 0.59722222, 0.68      , 0.5974026 , 0.67045455,\n",
       "          0.74117647, 0.68674699, 0.63414634, 0.64473684, 0.65517241]),\n",
       "   'train_precision': array([1.        , 1.        , 0.99958686, 0.99958609, 0.99979283,\n",
       "          0.99979279, 0.99979249, 0.99958609, 0.99958618, 0.99958609]),\n",
       "   'test_recall': array([0.07818182, 0.07818182, 0.09289617, 0.08378871, 0.10746812,\n",
       "          0.1147541 , 0.10382514, 0.09471767, 0.08925319, 0.10382514]),\n",
       "   'train_recall': array([0.97632537, 0.97511129, 0.97896015, 0.97713939, 0.97633016,\n",
       "          0.97612786, 0.97471171, 0.97713939, 0.9773417 , 0.97713939])}],\n",
       " [100,\n",
       "  None,\n",
       "  {'fit_time': array([52.47359467, 51.98531437, 52.57543206, 48.95297289, 48.20046115,\n",
       "          48.0131495 , 48.16723347, 49.04265547, 48.03725958, 48.43607783]),\n",
       "   'score_time': array([0.94449019, 0.72712374, 0.61262631, 0.69377398, 0.60166931,\n",
       "          0.60159588, 0.59960842, 0.60242748, 0.59833455, 0.62198925]),\n",
       "   'test_roc_auc': array([0.78128211, 0.7913602 , 0.78477082, 0.77080542, 0.79784844,\n",
       "          0.79627428, 0.78846099, 0.77854181, 0.78839113, 0.78987909]),\n",
       "   'train_roc_auc': array([0.99896406, 0.99896665, 0.99917744, 0.99907399, 0.99895585,\n",
       "          0.9990305 , 0.99897816, 0.99907529, 0.99907583, 0.99896896]),\n",
       "   'test_accuracy': array([0.93536211, 0.93854683, 0.93735992, 0.93476466, 0.93665212,\n",
       "          0.93901144, 0.93865031, 0.93735252, 0.93711656, 0.93605474]),\n",
       "   'train_accuracy': array([0.99847949, 0.99837462, 0.99861058, 0.99849261, 0.99845329,\n",
       "          0.99844018, 0.9984402 , 0.99850574, 0.99849263, 0.9984402 ]),\n",
       "   'test_precision': array([0.50714286, 0.60740741, 0.56923077, 0.48684211, 0.54166667,\n",
       "          0.61594203, 0.60902256, 0.55487805, 0.55633803, 0.52095808]),\n",
       "   'train_precision': array([0.99958592, 0.99958523, 0.99958686, 0.99979296, 0.99979283,\n",
       "          0.99958575, 0.99937888, 0.99958618, 0.99979296, 0.99958575]),\n",
       "   'test_recall': array([0.12909091, 0.14909091, 0.13479053, 0.13479053, 0.1420765 ,\n",
       "          0.15482696, 0.14754098, 0.16575592, 0.143898  , 0.15846995]),\n",
       "   'train_recall': array([0.97693242, 0.97531364, 0.97896015, 0.97693708, 0.97633016,\n",
       "          0.97633016, 0.97653247, 0.9773417 , 0.97693708, 0.97633016])}],\n",
       " [200,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([16.88991714, 16.15531349, 17.25767183, 16.0572176 , 16.14607453,\n",
       "          16.09076548, 16.07183242, 16.75425291, 16.23703265, 17.35864019]),\n",
       "   'score_time': array([1.43190479, 1.42781472, 1.38274431, 2.50950527, 1.38953257,\n",
       "          1.38251352, 1.49155688, 1.53517556, 1.38802195, 1.3891499 ]),\n",
       "   'test_roc_auc': array([0.80305442, 0.81290512, 0.7986056 , 0.7880478 , 0.81226197,\n",
       "          0.81509404, 0.81455543, 0.79763383, 0.81337664, 0.81552075]),\n",
       "   'train_roc_auc': array([0.99916356, 0.99926875, 0.99937127, 0.99930321, 0.99920829,\n",
       "          0.9992301 , 0.99922091, 0.99924164, 0.99931102, 0.9992154 ]),\n",
       "   'test_accuracy': array([0.93724935, 0.93748526, 0.93889348, 0.93665212, 0.93759585,\n",
       "          0.94113484, 0.93900425, 0.93888627, 0.93876829, 0.93924021]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99847951,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.61538462, 0.62820513, 0.67816092, 0.56521739, 0.59615385,\n",
       "          0.76041667, 0.67021277, 0.67032967, 0.65306122, 0.67346939]),\n",
       "   'train_precision': array([0.99979317, 1.        , 0.99979343, 1.        , 1.        ,\n",
       "          1.        , 0.99958584, 0.99958635, 1.        , 1.        ]),\n",
       "   'test_recall': array([0.08727273, 0.08909091, 0.10746812, 0.09471767, 0.1129326 ,\n",
       "          0.13296903, 0.1147541 , 0.11111111, 0.11657559, 0.12021858]),\n",
       "   'train_recall': array([0.9781465 , 0.97571833, 0.97916245, 0.9773417 , 0.97653247,\n",
       "          0.97633016, 0.97653247, 0.97774631, 0.9773417 , 0.97693708])}],\n",
       " [200,\n",
       "  'log2',\n",
       "  {'fit_time': array([14.03870583, 15.08806562, 14.18759036, 14.15712786, 13.82458019,\n",
       "          13.87329221, 13.72226429, 13.86636066, 15.14586878, 14.08965206]),\n",
       "   'score_time': array([1.40442753, 1.42876172, 1.42513394, 1.48924518, 1.78036761,\n",
       "          1.42195463, 1.44271898, 1.42397594, 1.4199245 , 1.55064058]),\n",
       "   'test_roc_auc': array([0.80458559, 0.81508417, 0.80137035, 0.78389005, 0.81671691,\n",
       "          0.81959781, 0.81201517, 0.7979723 , 0.81626731, 0.81111316]),\n",
       "   'train_roc_auc': array([0.99921335, 0.99924824, 0.9993766 , 0.99931264, 0.9992395 ,\n",
       "          0.99924478, 0.99921069, 0.9992667 , 0.99933583, 0.99923174]),\n",
       "   'test_accuracy': array([0.9371314 , 0.93748526, 0.93818568, 0.93665212, 0.93735992,\n",
       "          0.94101687, 0.93947617, 0.93711656, 0.93924021, 0.93829637]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.62318841, 0.63888889, 0.66233766, 0.57692308, 0.60714286,\n",
       "          0.78823529, 0.73076923, 0.58510638, 0.70238095, 0.63829787]),\n",
       "   'train_precision': array([1.        , 1.        , 1.        , 1.        , 0.99979296,\n",
       "          0.99979287, 0.99958584, 0.99979309, 1.        , 1.        ]),\n",
       "   'test_recall': array([0.07818182, 0.08363636, 0.09289617, 0.08196721, 0.09289617,\n",
       "          0.12204007, 0.10382514, 0.10018215, 0.10746812, 0.10928962]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97693708,\n",
       "          0.97653247, 0.97653247, 0.977544  , 0.9773417 , 0.97693708])}],\n",
       " [200,\n",
       "  None,\n",
       "  {'fit_time': array([96.32272148, 94.07389879, 94.91486216, 96.18113112, 94.08571148,\n",
       "          97.63220501, 94.53732419, 94.5298202 , 96.68483829, 94.14158559]),\n",
       "   'score_time': array([1.1947639 , 1.18007374, 1.18248153, 1.20731378, 1.19408751,\n",
       "          1.26380301, 1.33187556, 1.21061707, 1.17630768, 1.20890903]),\n",
       "   'test_roc_auc': array([0.78433733, 0.80190372, 0.78357483, 0.7727496 , 0.7999986 ,\n",
       "          0.79909796, 0.79466273, 0.78217744, 0.79364306, 0.79250023]),\n",
       "   'train_roc_auc': array([0.99897441, 0.99902731, 0.99923748, 0.99910883, 0.99899308,\n",
       "          0.99906794, 0.99903464, 0.99908265, 0.99916046, 0.99902391]),\n",
       "   'test_accuracy': array([0.93571597, 0.93842887, 0.93735992, 0.93464669, 0.93629822,\n",
       "          0.93995517, 0.93817839, 0.93735252, 0.93770647, 0.93758849]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99849263]),\n",
       "   'test_precision': array([0.51798561, 0.60606061, 0.56923077, 0.48148148, 0.52980132,\n",
       "          0.64925373, 0.59398496, 0.55487805, 0.57664234, 0.5625    ]),\n",
       "   'train_precision': array([1.        , 1.        , 0.99979343, 1.        , 0.99958609,\n",
       "          1.        , 1.        , 0.99979309, 0.99979309, 1.        ]),\n",
       "   'test_recall': array([0.13090909, 0.14545455, 0.13479053, 0.11839709, 0.14571949,\n",
       "          0.15846995, 0.143898  , 0.16575592, 0.143898  , 0.16393443]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97916245, 0.9773417 , 0.97713939,\n",
       "          0.97633016, 0.97612786, 0.977544  , 0.977544  , 0.97673478])}],\n",
       " [1000,\n",
       "  'sqrt',\n",
       "  {'fit_time': array([83.35066772, 82.1224792 , 83.83868337, 81.77533221, 82.02014112,\n",
       "          83.79094911, 85.14308834, 92.43937278, 83.16639614, 86.43093657]),\n",
       "   'score_time': array([7.21336317, 7.12609363, 7.46482182, 7.09864497, 7.61605334,\n",
       "          7.15576816, 7.12252116, 7.38745117, 7.01713896, 9.39694786]),\n",
       "   'test_roc_auc': array([0.80750206, 0.81577206, 0.80336117, 0.78974328, 0.81763766,\n",
       "          0.82083745, 0.81427394, 0.80104071, 0.8162209 , 0.81395271]),\n",
       "   'train_roc_auc': array([0.99922036, 0.99926115, 0.99939184, 0.99931951, 0.99922704,\n",
       "          0.99926032, 0.999247  , 0.99926643, 0.9993434 , 0.99923703]),\n",
       "   'test_accuracy': array([0.93701345, 0.93748526, 0.93853958, 0.93665212, 0.93830365,\n",
       "          0.9408989 , 0.93959415, 0.93770647, 0.93959415, 0.93900425]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.59756098, 0.62820513, 0.6627907 , 0.56666667, 0.62745098,\n",
       "          0.75531915, 0.69473684, 0.60824742, 0.69473684, 0.67021277]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.08909091, 0.08909091, 0.10382514, 0.09289617, 0.11657559,\n",
       "          0.12932605, 0.12021858, 0.10746812, 0.12021858, 0.1147541 ]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}],\n",
       " [1000,\n",
       "  'log2',\n",
       "  {'fit_time': array([ 91.30245781, 100.66317987,  88.68085146,  74.25791669,\n",
       "           78.75498533,  75.61559653,  76.74828649,  72.60451078,\n",
       "           81.01999259,  73.73780131]),\n",
       "   'score_time': array([9.66082907, 8.14773297, 7.39311647, 7.43675637, 8.21505666,\n",
       "          8.47682953, 8.75386524, 7.53796721, 8.06954622, 7.58465791]),\n",
       "   'test_roc_auc': array([0.80724349, 0.81805603, 0.80368685, 0.79122094, 0.81902434,\n",
       "          0.82027191, 0.81571848, 0.80229809, 0.81745426, 0.8159794 ]),\n",
       "   'train_roc_auc': array([0.99925039, 0.99928378, 0.99941296, 0.99934645, 0.99925328,\n",
       "          0.99929125, 0.99927709, 0.99928105, 0.99936303, 0.99926005]),\n",
       "   'test_accuracy': array([0.93701345, 0.93701345, 0.93842161, 0.93665212, 0.93783178,\n",
       "          0.94019111, 0.93912223, 0.93735252, 0.93888627, 0.93876829]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.61428571, 0.60810811, 0.68      , 0.57894737, 0.62222222,\n",
       "          0.74418605, 0.71428571, 0.6       , 0.68674699, 0.6744186 ]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.07818182, 0.08181818, 0.09289617, 0.08014572, 0.10200364,\n",
       "          0.11657559, 0.10018215, 0.09836066, 0.10382514, 0.10564663]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}],\n",
       " [1000,\n",
       "  None,\n",
       "  {'fit_time': array([ 533.1738143 ,  506.2536633 ,  492.91550231,  486.5309217 ,\n",
       "           957.53897643,  522.35984731,  492.65388012,  982.35089016,\n",
       "          2168.53665113,  983.43033648]),\n",
       "   'score_time': array([ 6.77443004,  6.17230916,  6.97112751,  6.11215091, 14.2206285 ,\n",
       "           6.12467408,  6.5910511 , 13.9248755 , 13.70360565, 10.68248868]),\n",
       "   'test_roc_auc': array([0.78780616, 0.80351355, 0.78592131, 0.7727527 , 0.80067718,\n",
       "          0.79856344, 0.7975711 , 0.78683791, 0.79502268, 0.79568687]),\n",
       "   'train_roc_auc': array([0.99900407, 0.99904032, 0.99924474, 0.99911954, 0.99901425,\n",
       "          0.9990636 , 0.99903427, 0.99909323, 0.99916122, 0.99902446]),\n",
       "   'test_accuracy': array([0.93642368, 0.93795707, 0.93759585, 0.93511856, 0.93747788,\n",
       "          0.93983721, 0.93817839, 0.93876829, 0.93782445, 0.93723454]),\n",
       "   'train_accuracy': array([0.99857124, 0.99842705, 0.9986368 , 0.99853194, 0.99849261,\n",
       "          0.9984664 , 0.99845331, 0.99853196, 0.99853196, 0.99850574]),\n",
       "   'test_precision': array([0.54198473, 0.5952381 , 0.58064516, 0.49640288, 0.56551724,\n",
       "          0.64885496, 0.59689922, 0.59146341, 0.58088235, 0.55414013]),\n",
       "   'train_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "   'test_recall': array([0.12909091, 0.13636364, 0.13114754, 0.12568306, 0.14936248,\n",
       "          0.15482696, 0.14025501, 0.17668488, 0.143898  , 0.15846995]),\n",
       "   'train_recall': array([0.97794415, 0.97571833, 0.97896015, 0.9773417 , 0.97673478,\n",
       "          0.97633016, 0.97612786, 0.9773417 , 0.9773417 , 0.97693708])}]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer, Categorical, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [Integer(10, 60, name='n_estimators'),\n",
    "         Categorical(['sqrt', 'log2'], name='max_features'),\n",
    "         Categorical(['gini','entropy'], name='criterion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    return -np.mean(cross_val_score(rf, tr[cols], tr['HighUtilizationY2'], cv=5, n_jobs=1, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gp = gp_minimize(objective, space, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
