{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth',100 )\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\akhil\\\\Desktop\\\\Research\\\\Phase 2\\\\Phase2data.csv\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_textmain(text):\n",
    "    text = text.lower()\n",
    "    text =\"\".join([char for char in text if char not in string.punctuation ])\n",
    "    text=re.sub(r'\\b\\w{1,4}\\b', '',text)\n",
    "    result = re.sub(r'[0-9]+','',text)\n",
    "    tokens = re.split('\\W+', result)\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    text1=[word for word in words if word not in string.digits]\n",
    "    #text = [ps.stem(word) for word in text1 if word not in stopwords]\n",
    "    text = [wn.lemmatize(word) for word in text1 if word not in stopwords]\n",
    "    op = list(nltk.bigrams(text))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigram'] = df.Title.apply(clean_textmain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Citaions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference Name</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Achieving Meaningful Privacy in Digital Systems</td>\n",
       "      <td>0</td>\n",
       "      <td>H Nissenbaum</td>\n",
       "      <td>25th CCS 2018:\\r\\nToronto, ON, Canada</td>\n",
       "      <td>2018</td>\n",
       "      <td>CCS</td>\n",
       "      <td>[(achieving, meaningful), (meaningful, privacy), (privacy, digital), (digital, system)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Towards Fine-grained Network Security Forensics and Diagnosis in the SDN Era</td>\n",
       "      <td>0</td>\n",
       "      <td>H Wang, G Yang, P Chinprutthiwong, L Xua</td>\n",
       "      <td>25th CCS 2018:\\r\\nToronto, ON, Canada</td>\n",
       "      <td>2018</td>\n",
       "      <td>CCS</td>\n",
       "      <td>[(towards, finegrained), (finegrained, network), (network, security), (security, forensics), (fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vNIDS: Towards Elastic Security with Safe and Efficient Virtualization of Network Intrusion Dete...</td>\n",
       "      <td>0</td>\n",
       "      <td>H Li, H Hu, G Gu, GJ Ahn, F Zhang</td>\n",
       "      <td>25th CCS 2018:\\r\\nToronto, ON, Canada</td>\n",
       "      <td>2018</td>\n",
       "      <td>CCS</td>\n",
       "      <td>[(vnids, towards), (towards, elastic), (elastic, security), (security, efficient), (efficient, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABY 3: a mixed protocol framework for machine learning</td>\n",
       "      <td>3</td>\n",
       "      <td>P Mohassel, P Rindal</td>\n",
       "      <td>25th CCS 2018:\\r\\nToronto, ON, Canada</td>\n",
       "      <td>2018</td>\n",
       "      <td>CCS</td>\n",
       "      <td>[(mixed, protocol), (protocol, framework), (framework, machine), (machine, learning)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voting: You Can't Have Privacy without Individual Verifiability</td>\n",
       "      <td>0</td>\n",
       "      <td>V Cortier, J Lallemand</td>\n",
       "      <td>25th CCS 2018:\\r\\nToronto, ON, Canada</td>\n",
       "      <td>2018</td>\n",
       "      <td>CCS</td>\n",
       "      <td>[(voting, privacy), (privacy, without), (without, individual), (individual, verifiability)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 Title  \\\n",
       "0                                                      Achieving Meaningful Privacy in Digital Systems   \n",
       "1                         Towards Fine-grained Network Security Forensics and Diagnosis in the SDN Era   \n",
       "2  vNIDS: Towards Elastic Security with Safe and Efficient Virtualization of Network Intrusion Dete...   \n",
       "3                                               ABY 3: a mixed protocol framework for machine learning   \n",
       "4                                      Voting: You Can't Have Privacy without Individual Verifiability   \n",
       "\n",
       "   Citaions                                   Authors  \\\n",
       "0         0                              H Nissenbaum   \n",
       "1         0  H Wang, G Yang, P Chinprutthiwong, L Xua   \n",
       "2         0         H Li, H Hu, G Gu, GJ Ahn, F Zhang   \n",
       "3         3                      P Mohassel, P Rindal   \n",
       "4         0                    V Cortier, J Lallemand   \n",
       "\n",
       "                              Conference  Year Conference Name  \\\n",
       "0  25th CCS 2018:\\r\\nToronto, ON, Canada  2018             CCS   \n",
       "1  25th CCS 2018:\\r\\nToronto, ON, Canada  2018             CCS   \n",
       "2  25th CCS 2018:\\r\\nToronto, ON, Canada  2018             CCS   \n",
       "3  25th CCS 2018:\\r\\nToronto, ON, Canada  2018             CCS   \n",
       "4  25th CCS 2018:\\r\\nToronto, ON, Canada  2018             CCS   \n",
       "\n",
       "                                                                                                bigram  \n",
       "0              [(achieving, meaningful), (meaningful, privacy), (privacy, digital), (digital, system)]  \n",
       "1  [(towards, finegrained), (finegrained, network), (network, security), (security, forensics), (fo...  \n",
       "2  [(vnids, towards), (towards, elastic), (elastic, security), (security, efficient), (efficient, v...  \n",
       "3                [(mixed, protocol), (protocol, framework), (framework, machine), (machine, learning)]  \n",
       "4          [(voting, privacy), (privacy, without), (without, individual), (individual, verifiability)]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ('image','classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flagged'] = df['bigram'].apply(lambda x: 1 if test in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.where(df['flagged'] == 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly use citation as weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016., 2015., 2006., 2017., 2014., 2013., 2012., 2011., 2010.,\n",
       "       2009., 2008., 2007., 1999., 1995., 1993., 2018., 2005., 2002.,\n",
       "       2001.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "years =df_2['Year'].unique().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2015\n",
      "2006\n",
      "2017\n",
      "2014\n",
      "2013\n",
      "2012\n",
      "2011\n",
      "2010\n",
      "2009\n",
      "2008\n",
      "2007\n",
      "1999\n",
      "1995\n",
      "1993\n",
      "2018\n",
      "2005\n",
      "2002\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "for i in years:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df_2.groupby('Year').get_group(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "for x,y in zip(df_2018['bigram'], df_2018['Citaions']):\n",
    "    for item in x:\n",
    "        if item == test:\n",
    "            continue\n",
    "        d[item] += y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x':list(d.keys()), 'y': list(d.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_d = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = plot_d.sort_values(by=['y'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = zz.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz['x1'] = zz['x'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27         finegrained image\n",
       "40    embeddings finegrained\n",
       "39         output embeddings\n",
       "38         evaluation output\n",
       "29            learning image\n",
       "26       network finegrained\n",
       "25            neural network\n",
       "24      convolutional neural\n",
       "23       model convolutional\n",
       "22           attention model\n",
       "Name: x1, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz['x1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finegrained image 575.0\n",
      "embeddings finegrained 260.0\n",
      "output embeddings 260.0\n",
      "evaluation output 260.0\n",
      "learning image 236.0\n",
      "network finegrained 227.0\n",
      "neural network 227.0\n",
      "convolutional neural 227.0\n",
      "model convolutional 227.0\n",
      "attention model 227.0\n"
     ]
    }
   ],
   "source": [
    "for i,x in zz.iterrows():\n",
    "    print(x['x1'], x['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    575.0\n",
       "40    260.0\n",
       "39    260.0\n",
       "38    260.0\n",
       "29    236.0\n",
       "26    227.0\n",
       "25    227.0\n",
       "24    227.0\n",
       "23    227.0\n",
       "22    227.0\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz['y']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(zz['x1'], zz['y'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Top 10 Related Topics', fontsize=18)\n",
    "plt.ylabel('Citaions', fontsize=16)\n",
    "plt.title('Topic : Semantic Segmentation - 2015', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
